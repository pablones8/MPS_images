{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of MNIST binary dataset using MPS encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "from MPS_functions import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import AdamOptimizer\n",
    "from sklearn import svm\n",
    "import math\n",
    "\n",
    "np.random.seed(88)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of original training examples: 60000\n",
      "Number of original test examples: 10000\n"
     ]
    }
   ],
   "source": [
    "with np.load('mnist.npz', allow_pickle=True) as f:\n",
    "    x_train, y_train = f['x_train'], f['y_train']\n",
    "    x_test, y_test = f['x_test'], f['y_test']\n",
    "\n",
    "# Rescale the images from [0,255] to the [0,1] range.\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "print(\"Number of original training examples:\", len(x_train))\n",
    "print(\"Number of original test examples:\", len(x_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We filter only two classes for binary classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose two numbers: number_0 and number_1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_0 = 3; number_1 = 9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_01(x, y, number_0, number_1):\n",
    "    keep = (y == number_0) | (y == number_1)\n",
    "    x, y = x[keep], y[keep]\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of filtered training examples: 12080\n",
      "Number of filtered test examples: 2019\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = filter_01(x_train, y_train, number_0, number_1)\n",
    "x_test, y_test = filter_01(x_test, y_test, number_0, number_1)\n",
    "\n",
    "print(\"Number of filtered training examples:\", len(x_train))\n",
    "print(\"Number of filtered test examples:\", len(x_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels must be 0's and 1's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.where(y_test == number_0, 0, y_test)\n",
    "y_test = np.where(y_test == number_1, 1, y_test)\n",
    "y_test = np.array(y_test, requires_grad=False)\n",
    "\n",
    "y_train = np.where(y_train == number_0, 0, y_train)\n",
    "y_train = np.where(y_train == number_1, 1, y_train)\n",
    "y_train = np.array(y_train, requires_grad=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take random training and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28, 28)\n",
      "(2000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "def random_subset(x, y, n):\n",
    "    indices = np.random.choice(len(x), n, replace=False)\n",
    "    return x[indices], y[indices]\n",
    "\n",
    "# Set your desired number of samples\n",
    "n_train = 1000\n",
    "n_test = 2000\n",
    "\n",
    "x_train, y_train = random_subset(x_train, y_train, n_train)\n",
    "x_test, y_test = random_subset(x_test, y_test, n_test)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the superposition state \n",
    "\n",
    "We need $L=\\left \\lceil{\\log_2(28\\times 28)}\\right \\rceil = 10$ qubits for the image loading. We define the 10-qubit quantum state:\n",
    "$$\n",
    "\\begin{align}\n",
    "|\\psi\\rangle=\\frac{|z\\rangle + |W\\rangle}{\\sqrt{2}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Where:\\\n",
    "$\\bullet |z\\rangle =$ image from left to right and up to down\\\n",
    "$\\bullet |W\\rangle =$ image from up to down and left to right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unnormalized |z> and |W>\n",
    "def encode_mnist_states(images, reading_order=\"left_to_right_up_to_down\"):\n",
    "    n_samples, n_rows, n_cols = images.shape\n",
    "\n",
    "    encoding_qubits=math.ceil(math.log2(n_rows*n_cols))\n",
    "    state_dim = 2 ** encoding_qubits  \n",
    "\n",
    "    encoded_states = np.zeros((n_samples, state_dim))\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        state = np.zeros(state_dim)\n",
    "        index = 0\n",
    "\n",
    "        if reading_order == \"left_to_right_up_to_down\":\n",
    "            for row in range(n_rows):\n",
    "                for col in range(n_cols):\n",
    "                    state[index] = image[row, col]\n",
    "                    index += 1\n",
    "        elif reading_order == \"up_to_down_left_to_right\":\n",
    "            for col in range(n_cols):\n",
    "                for row in range(n_rows):\n",
    "                    state[index] = image[row, col]\n",
    "                    index += 1\n",
    "        else:\n",
    "            raise ValueError(\"Invalid reading_order. Choose 'left_to_right_up_to_down' or 'up_to_down_left_to_right'.\")\n",
    "\n",
    "        encoded_states[i, :] = state\n",
    "\n",
    "    return encoded_states\n",
    "\n",
    "train_left_right = encode_mnist_states(x_train, reading_order=\"left_to_right_up_to_down\")\n",
    "train_up_down = encode_mnist_states(x_train, reading_order=\"up_to_down_left_to_right\")\n",
    "\n",
    "test_left_right = encode_mnist_states(x_test, reading_order=\"left_to_right_up_to_down\")\n",
    "test_up_down = encode_mnist_states(x_test, reading_order=\"up_to_down_left_to_right\")\n",
    "\n",
    "\n",
    "# Create the superposition quantum state\n",
    "def create_normalized_vectors(encoded_states_left_right, encoded_states_up_down):\n",
    "    normalized_vectors = []\n",
    "    for i in range(len(encoded_states_left_right)):\n",
    "        left_right = encoded_states_left_right[i]\n",
    "        up_down = encoded_states_up_down[i]\n",
    "        \n",
    "        # Sum the corresponding elements from both arrays\n",
    "        combined = np.add(left_right, up_down)\n",
    "        \n",
    "        # Normalization\n",
    "        l2_norm = np.linalg.norm(combined, ord=2)\n",
    "        normalized_vector = combined / l2_norm\n",
    "        \n",
    "        normalized_vectors.append(normalized_vector)\n",
    "    \n",
    "    return np.array(normalized_vectors, requires_grad = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and test sets containing the superposition quantum states $|\\psi\\rangle$ of the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_states = create_normalized_vectors(train_left_right, train_up_down)\n",
    "test_states = create_normalized_vectors(test_left_right, test_up_down)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasical benchmark using these arrays to perform classification\n",
    "\n",
    "We are using state $|\\psi\\rangle$ as input for the clasical model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This linear model uses a numper of parameters p=n_features+1\\\n",
    "In our case this is 1024+1=1025 trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9665\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Replace with your data loading code\n",
    "X_train = training_states\n",
    "X_test = test_states\n",
    "\n",
    "# Create a LogisticRegression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the MPS approximation of the image states\n",
    "\n",
    "We will use the approximated states\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "|\\tilde{\\psi}\\rangle=\\text{MPS}_\\chi (|\\psi\\rangle)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $\\chi$ is the bond dimension which controls the degree of compression of the image."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_2(exact,approximate):\n",
    "    length = len(exact)\n",
    "    sum = 0\n",
    "    for i in range(length):\n",
    "        sum = sum + (exact[i]-approximate[i])**2\n",
    "    return np.sqrt(sum/length)[0]\n",
    "\n",
    "def fidelity(exact,approximate):\n",
    "    return np.abs(exact @ approximate)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi =1\n",
      "Fidelity:  0.26938966383054375\n",
      "L2 norm:  0.03064961976767334\n",
      "\n",
      "Chi =2\n",
      "Fidelity:  0.4329252552066784\n",
      "L2 norm:  0.0258462038583748\n",
      "\n",
      "Chi =4\n",
      "Fidelity:  0.7252576143587157\n",
      "L2 norm:  0.017023617485813113\n",
      "\n",
      "Chi =8\n",
      "Fidelity:  0.9144238715711407\n",
      "L2 norm:  0.009243332804952143\n",
      "\n",
      "Chi =16\n",
      "Fidelity:  0.9975186082969193\n",
      "L2 norm:  0.0015571574105562739\n",
      "\n",
      "Chi =32\n",
      "Fidelity:  1.0000000000000027\n",
      "L2 norm:  1.0175162965938628e-16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "L = 10; d = 2; chis = [1,2,4,8,16,32]\n",
    "\n",
    "# We take an element of the training set as an example\n",
    "state = training_states[0]\n",
    "\n",
    "for chi in chis:\n",
    "    mps = MPS(state, L, d, chi)\n",
    "    approx_state = MPS_contraction(mps, L, d)\n",
    "    fid = fidelity(state,approx_state)\n",
    "    L2_norm = norm_2(state,approx_state)\n",
    "    print('Chi ='+ str(chi))\n",
    "    print('Fidelity: ', fid[0])\n",
    "    print('L2 norm: ', L2_norm)\n",
    "    print('')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we choose a $\\chi$ and we obtain the correspondent approximated training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi = 1\n",
    "\n",
    "training_approx_states = []\n",
    "test_approx_states = []\n",
    "\n",
    "for element in training_states:\n",
    "    mps = MPS(element, L, d, chi)\n",
    "    approximation = MPS_contraction(mps, L, d)\n",
    "    approximation = np.reshape(approximation, (1, -1))\n",
    "    training_approx_states.append(approximation[0])\n",
    "\n",
    "for element in test_states:\n",
    "    mps = MPS(element, L, d, chi)\n",
    "    approximation = MPS_contraction(mps, L, d)\n",
    "    approximation = np.reshape(approximation, (1, -1))\n",
    "    test_approx_states.append(approximation[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasical benchmark with the approximation state $|\\tilde{\\psi}\\rangle$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.796\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(training_approx_states, y_train)\n",
    "y_pred = model.predict(test_approx_states)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_1 = training_approx_states[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that Pennylane does not try to compute the grad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(training_approx_states, requires_grad=False)\n",
    "x_test = np.array(test_approx_states, requires_grad=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of layes of the model\n",
    "# The number of trainabla parameters will be 3*layers*loading_qubits\n",
    "layers = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we present the variational quantum circuit which will be used as QNN\\\n",
    "We assume it is initialized with $|\\tilde{\\psi}\\rangle$ loaded in the amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need L = 10 qubits to encode the image using MPS and one extra qubit to perform classification\n",
    "\n",
    "loading_qubits = int(np.log2(len(training_states[0])))\n",
    "qubits = int(loading_qubits+1) \n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=qubits)\n",
    "@qml.qnode(dev, interface=\"autograd\")\n",
    "def QNN(params, x, y):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        params: array of parameters\n",
    "        x: single input vector\n",
    "        y: single output state density matrix corresponding to each label\n",
    "\n",
    "    Returns: fidelity between output state and input\n",
    "    \"\"\"\n",
    "    loading_qubits = int(np.log2(len(x)))\n",
    "    qml.AmplitudeEmbedding(x, wires=list(range(loading_qubits)))\n",
    "\n",
    "    for p in range(len(params)):\n",
    "        qml.CRot(params[p][0],params[p][1],params[p][2], wires=[p,loading_qubits])\n",
    "\n",
    "    return qml.expval(qml.Hermitian(y, wires=[loading_qubits]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need L = 10 qubits to encode the image using MPS and one extra qubit to perform classification\n",
    "\n",
    "loading_qubits = int(np.log2(len(training_states[0])))\n",
    "qubits = int(loading_qubits+1) \n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=qubits)\n",
    "@qml.qnode(dev, interface=\"autograd\")\n",
    "def QNN(params, x, y):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        params: array of parameters\n",
    "        x: single input vector\n",
    "        y: single output state density matrix corresponding to each label\n",
    "\n",
    "    Returns: fidelity between output state and input\n",
    "    \"\"\"\n",
    "    loading_qubits = int(np.log2(len(x)))\n",
    "    layers = np.shape(params)[0]//loading_qubits\n",
    "\n",
    "    qml.AmplitudeEmbedding(x, wires=list(range(loading_qubits)))\n",
    "\n",
    "    for j in range(layers):\n",
    "        for p in range(loading_qubits):\n",
    "            qml.CRot(params[j*loading_qubits+p][0],params[j*loading_qubits+p][1],params[j*loading_qubits+p][2], wires=[p,loading_qubits])\n",
    "\n",
    "    return qml.expval(qml.Hermitian(y, wires=[loading_qubits]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification qubits assigns labels according to the fidelity with respect to the label states $|0\\rangle$ and $|1\\rangle$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_0 = [[1,0],[0,0]]\n",
    "label_1 = [[0,0],[0,1]]\n",
    "dm_labels = [label_0, label_1]\n",
    "dm_labels = np.array(dm_labels, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<Figure size 1400x1200 with 1 Axes>, <Axes: >)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABYwAAATECAYAAADI00FuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAACMRUlEQVR4nOzdfXzddWH3//cpCRnprVaIcHEP7sYLkoItWiFFQdAxRJhT0A2EalEh7aw623pdVuzEthvIIEQdhVLEbQ506i4VYdw2QL0J2ERxKgW5ETQwkEpbbQ70/P7w2B+VUnraJN/cPJ+PB49Hc24+e4dTZvvq6feUKpVKJQAAAAAAjHpjih4AAAAAAMDQIBgDAAAAAJBEMAYAAAAAoEowBgAAAAAgiWAMAAAAAECVYAwAAAAAQBLBGAAAAACAKsEYAAAAAIAkgjEAAAAAAFWCMQAAAAAASQRjAAAAAACqBGMAAAAAAJIIxgAAAAAAVAnGAAAAAAAkEYwBAAAAAKgSjAEAAAAASCIYAwAAAABQJRgDAAAAAJBEMAYAAAAAoEowBgAAAAAgiWAMAAAAAECVYAwAAAAAQBLBGAAAAACAKsEYAAAAAIAkgjEAAAAAAFWCMQAAAAAASQRjAAAAAACqBGMAAAAAAJIIxgAAAAAAVAnGAAAAAAAkEYwBAAAAAKgSjAEAAAAASCIYAwAAAABQJRgDAAAAAJBEMAYAAAAAoEowBgAAAAAgiWAMAAAAAECVYAwAAAAAQBLBGAAAAACAKsEYAAAAAIAkgjEAAAAAAFWCMQAAAAAASQRjAAAAAACqBGMAAAAAAJIIxgAAAAAAVAnGAAAAAAAkEYwBAAAAAKgSjAEAAAAASCIYAwAAAABQJRgDAAAAAJBEMAYAAAAAoEowBgAAAAAgiWAMAAAAAECVYAwAAAAAQBLBGAAAAACAKsEYAAAAAIAkgjEAAAAAAFWCMQAAAAAASQRjAAAAAACqBGMAAAAAAJIIxgAAAAAAVAnGAAAAAAAkEYwBAAAAAKgSjAEAAAAASCIYAwAAAABQJRgDAAAAAJBEMAYAAAAAoEowBgAAAAAgiWAMAAAAAEBVXdEDYDBs3Lgx999/f+69996sWbMm//M//5Pf/va32bhxY9HTttDQ0JA/+qM/yste9rIcfPDBecUrXpEDDzwwDQ0NRU8DAAAAYBQQjBmRnnnmmdx222259tprc/311+fBBx9MpVIpetYOKZVK2W+//fLGN74xb3vb23L00Uenrs5/ugAAAAD0v1JluFY02Io1a9bkwgsvzJe//OU8/vjjRc8ZELvvvnve+ta35sMf/nAOOuigoucAAAAAMIIIxowIGzZsyJIlS7J06dL09fUVPWdQNDQ05CMf+Ujmz5+fxsbGoucAAAAAMAIIxgx7N9xwQ84+++w8+OCDL/rYpqamHHzwwdlnn33S2NiYXXfdNWPGDI3Pfty0aVP6+vqyYcOGPPzww1mzZk16e3tf9Hn7779//vmf/znHH3/8IKwEAAAAYCQTjBnWvvKVr+Ttb397nnnmma3e/6pXvSpve9vb8oY3vCGveMUrMmHChEFeuHN+/etf5957782NN96Ya665JnffffdWH1dXV5drrrkmp5xyyiAvBAAAAGAkEYwZtl4oFu+yyy6ZPXt2Zs+enQMPPLCgdQPjvvvuy6WXXpr29vY8++yzW9wnGgMAAACwswRjhqUbbrghf/EXf/G8WDxjxox0dHTkkEMOKWjZ4PjhD3+Yc889NytXrtzi9rq6unzjG99weQoAAAAAdohgzLCzYcOGvPKVr3zeNYtnzZqVz33uc0PmmsQDbdOmTXnf+96XZcuWbXH7/vvvnx/96EfZbbfdCloGAAAAwHA1OsoaI8qSJUtGfSxOkjFjxuRzn/tcZs2atcXtDzzwQJYsWVLQKgAAAACGM+8wZlhZs2ZNDjnkkGzcuHHzbTNmzMgtt9wyqmLxc23atCmve93r0tnZufm2hoaG3HPPPTnooIMKXAYAAADAcDM6CxvD1oUXXrhFLN5ll13S0dExamNx8rt3Gnd0dGSXXXbZfNvGjRtzwQUXFLgKAAAAgOFo9FY2hp1nnnkmX/7yl7e4bfbs2SP+A+62x6GHHprZs2dvcdt//Md/PO9DAQEAAABgWwRjho3bbrstjz/++Ba3/WEkHc3a2tq2+Pqxxx7LypUrC1oDAAAAwHAkGDNsXHvttVt8/apXvSoHHnhgQWuGnoMOOiiHH374Frf94b8zAAAAANgWwZhh4/rrr9/i67e97W0FLRm6/vDfyR/+OwMAAACAbRGMGRY2btyYBx98cIvb3vCGNxS0Zug67rjjtvj6wQcf3OJDAgEAAABgWwRjhoX7778/lUpli9v++I//uKA1Q9crXvGKLb7etGlTfvaznxW0BgAAAIDhRjBmWLj33nu3+LqpqSnjx48vaM3QNWHChOyxxx5b3PaH/+4AAAAA4IUIxgwLa9as2eLrgw8+uKAlQ98fvstYMAYAAABgewnGDAv/8z//s8XX++yzT0FLhr699957i6+feOKJgpYAAAAAMNwIxgwLv/3tb7f4urGxsaAlQ98f/rv5w393AAAAAPBCBGOGhY0bN27x9a677lrQkqGvoaFhi68FYwAAAAC2l2DMsDRmjJ+6L8S/GwAAAAB2lLIEAAAAAEASwRgAAAAAgCrBGAAAAACAJEld0QMA+ku5XM7TTz+dJBk/fnzq6+sLXgQAAAAwvHiHMTCsrV69OnPmzMm0adMybty4TJ48OZMnT864ceMybdq0zJkzJ93d3UXPBAAAABgWBGNgWOrp6cmMGTNy2GGHpb29PV1dXenr69t8f19fX7q6utLe3p4pU6ZkxowZ6enpKXAxAAAAwNAnGAPDSqVSyZIlSzJ16tR0dnZu9/M6OzszderULFmyJJVKZQAXAgAAAAxfgjEwbFQqlcyePTsLFixIuVyu+fnlcjkLFizI7NmzRWMAAACArRgVwfh73/teTjjhhEyaNCljx47Na17zmlxzzTVFzwJqtHTp0nR0dOz0OR0dHVm6dGk/LAIAAAAYWUZ8ML7lllty5JFH5vbbb8/b3/72vO9978svf/nLnHrqqbnwwguLngdsp56enixcuLDfzlu4cKFrGgMAAAD8gREdjJ955pnMmjUrY8aMycqVK3PZZZflwgsvTHd3d/74j/84H/3oR/Pggw8WPRPYDm1tbTt0GYoXUi6X09bW1m/nAQAAAIwEIzoY33zzzbnvvvvyzne+M1OmTNl8+8SJE/PRj340fX19ueqqq4obCGyX1atX1/QBd9urs7Mz3d3d/X4uAAAAwHA1ooPxrbfemiQ5/vjjn3ffG9/4xiTJbbfdNpiTgB2wfPnyYXk2AAAAwHAzooPxvffemyR5xSte8bz7Xv7yl2fcuHGbHwMMXatWrRqWZwMAAAAMN3VFDxhIa9euTfK7S1BszYQJEzY/ZrioVCrZsGFD0TMGXX9eu3a0KZfLWb9+fdEzdli5XB7QD6fr6enJ2rVrU1c3ov/fIQAAABSisbExpVKp6BnUQCEZZjZs2JBx48YVPYNhZNmyZVm2bFnRM4asjRs3ZtKkSUXPAAAAgBFp3bp1GTt2bNEzqMGIviTF799Z/ELvIv71r3/9gu8+BgAAAAAYbUb0O4x/f+3ie++9N6961au2uO+Xv/xl1q1blyOOOKKIaTussbEx69atK3rGoJs7d653ye6gWbNm5aKLLip6xg4rl8tpampKX1/fgJzf0NCQ3t5el6QAAACAAdDY2Fj0BGo0ogvJ0UcfncWLF+eGG27IaaedtsV9119//ebHDCelUmlUvo2/vr6+6AnDVn19/bD/OdPc3Jyurq4BO9vfNAAAAAD4nRF9SYpjjz02Bx54YP71X/81q1ev3nz72rVr86lPfSq77rprzjjjjOIGAttl+vTpw/JsAAAAgOFmRAfjurq6XH755dm0aVNmzJiRs88+Ox/60IfS0tKSn/70p/nUpz6V/fffv+iZwIuYOXPmsDwbAAAAYLgZ0cE4SV7/+tfn9ttvz5FHHpl///d/z2c/+9k0NTXli1/8Yj70oQ8VPQ/YDlOmTElra2u/n9va2pqWlpZ+PxcAAABguBrR1zD+vSOOOCLXXXdd0TOAnXDppZdm6tSpKZfL/XJefX19Ojo6+uUsAAAAgJFixL/DGBgZmpubs2jRon47b9GiRTn00EP77TwAAACAkUAwBoaNefPm5dxzz93pc9ra2jJv3rx+WAQAAAAwsgjGwLBRKpXS3t6exYsXp76+vubn19fXZ/HixbnkkktSKpUGYCEAAADA8CYYA8NKqVTK/Pnz09XVVdMH4bW2tuauu+7K/PnzxWIAAACAFzAqPvQOGHmam5uzcuXKdHd3Z/ny5Vm1alW6u7vT19eXJGloaEhzc3OmT5+emTNnpqWlpeDFAAAAAEOfYAwMay0tLbn44ouTJGvXrs2kSZOSJL29vZk4cWKBywAAAACGH5ekAEaMurq6rf4YAAAAgO0jGAMAAAAAkEQwBgAAAACgSjAGAAAAACCJYAwAAAAAQJVgDAAAAABAEsEYAAAAAIAqwRgAAAAAgCSCMQAAAAAAVYIxAAAAAABJBGMAAAAAAKoEYwAAAAAAkgjGAAAAAABUCcYAAAAAACQRjAEAAAAAqBKMAQAAAABIIhgDAAAAAFAlGAMAAAAAkEQwBgAAAACgSjAGAAAAACCJYAwAAAAAQJVgDAAAAABAEsEYAAAAAIAqwRgAAAAAgCSCMQAAAAAAVYIxAAAAAABJBGMAAAAAAKoEYwAAAAAAkgjGAAAAAABUCcYAAAAAACQRjAEAAAAAqBKMAQAAAABIIhgDAAAAAFAlGAMAAAAAkEQwBgAAAACgSjAGAAAAACCJYAwAAAAAQJVgDAAAAABAEsEYAAAAAIAqwRgAAAAAgCSCMQAAAAAAVYIxAAAAAABJBGMAAAAAAKoEYwAAAAAAkgjGAAAAAABUCcYAAAAAACQRjAEAAAAAqBKMAQAAAABIIhgDAAAAAFAlGAMAAAAAkEQwBgAAAACgSjAGAAAAACCJYAwAAAAAQJVgDAAAAABAEsEYAAAAAIAqwRgAAAAAgCSCMQAAAAAAVYIxAAAAAABJBGMAAAAAAKoEYwAAAAAAkgjGAAAAAABUCcYAAAAAACQRjAEAAAAAqBKMAQAAAABIIhgDAAAAAFAlGAMAAAAAkEQwBgAAAACgSjAGAAAAACCJYAwAAAAAQJVgDAAAAABAEsEYAAAAAIAqwRgAAAAAgCSCMQAAAAAAVYIxAAAAAABJkrqiBwAwMpXL5Tz99NNJkvHjx6e+vr7gRQAAAMCL8Q5jAPrN6tWrM2fOnEybNi3jxo3L5MmTM3ny5IwbNy7Tpk3LnDlz0t3dXfRMAAAA4AUIxgDstJ6ensyYMSOHHXZY2tvb09XVlb6+vs339/X1paurK+3t7ZkyZUpmzJiRnp6eAhcDAAAAWyMYA7DDKpVKlixZkqlTp6azs3O7n9fZ2ZmpU6dmyZIlqVQqA7gQAAAAqIVgDMAOqVQqmT17dhYsWJByuVzz88vlchYsWJDZs2eLxgAAADBEjPhg/IUvfCHvfe97M3Xq1DQ0NKRUKmXFihVFzwIY9pYuXZqOjo6dPqejoyNLly7th0UAAADAzhrxwfj//t//m8suuywPPvhg9txzz6LnAIwIPT09WbhwYb+dt3DhQtc0BgAAgCFgxAfjyy+/PA888EAef/zxvO997yt6DsCI0NbWtkOXoXgh5XI5bW1t/XYeAAAAsGNGfDB+wxvekP3226/oGQAjxurVq2v6gLvt1dnZme7u7n4/FwAAANh+Iz4YA9C/li9fPizPBgAAAF6cYAxATVatWjUszwYAAABeXF3RA6hNpVLJhg0bip4x6PrzWqmjTblczvr164ueMSie+32Olu95sJXL5QH9cLqenp6sXbs2dXX+5wkAAGAkaGxsTKlUKnoGNfA78mFmw4YNGTduXNEzGEaWLVuWZcuWFT1j0DU1NRU9gR2wcePGTJo0qegZAAAA9JN169Zl7NixRc+gBi5JAQAAAABAEu8wHnYaGxuzbt26omcMurlz547Kd8n2h1mzZuWiiy4qesagWL9+/eZ3Fvf29voTzAFQLpfT1NSUvr6+ATm/oaEhvb29LkkBAAAwQjQ2NhY9gRr5HfkwUyqVRmUEq6+vL3rCsFVfXz8qf86MHTt2VH7fg6G5uTldXV0DdvbEiRMH5GwAAADgxbkkBQA1mT59+rA8GwAAAHhxI/4dxpdffnluv/32JMkPfvCDzbfdeuutSZKjjjoq73nPe4qaBzDszJw5M+3t7QN2NgAAAFCcER+Mb7/99lx11VVb3HbHHXfkjjvu2Py1YAyw/aZMmZLW1tZ0dnb267mtra1paWnp1zMBAACA2oz4S1KsWLEilUrlBf9ZsWJF0RMBhp1LL720X68tXl9fn46Ojn47DwAAANgxIz4YA9D/mpubs2jRon47b9GiRTn00EP77TwAAABgxwjGAOyQefPm5dxzz93pc9ra2jJv3rx+WAQAAADsLMEYgB1SKpXS3t6exYsX79DlKerr67N48eJccsklKZVKA7AQAAAAqJVgDMAOK5VKmT9/frq6utLa2rrdz2ttbc1dd92V+fPni8UAAAAwhNQVPQCA4a+5uTkrV65Md3d3li9fnlWrVqW7uzt9fX1JkoaGhjQ3N2f69OmZOXNmWlpaCl4MAAAAbI1gDEC/aWlpycUXX5wkWbt2bSZNmpQk6e3tzcSJEwtcBgAAAGwPl6QAYEDU1dVt9ccAAADA0CUYAwAAAACQRDAGAAAAAKBKMAYAAAAAIIlgDAAAAABAlWAMAAAAAEASwRgAAAAAgCrBGAAAAACAJIIxAAAAAABVgjEAAAAAAEkEYwAAAAAAqgRjAAAAAACSCMYAAAAAAFQJxgAAAAAAJBGMAQAAAACoEowBAAAAAEgiGAMAAAAAUCUYAwAAAACQRDAGAAAAAKBKMAYAAAAAIIlgDAAAAABAlWAMAAAAAEASwRgAAAAAgCrBGAAAAACAJIIxAAAAAABVgjEAAAAAAEkEYwAAAAAAqgRjAAAAAACSCMYAAAAAAFQJxgAAAAAAJBGMAQAAAACoEowBAAAAAEgiGAMAAAAAUCUYAwAAAACQRDAGAAAAAKBKMAYAAAAAIIlgDAAAAABAlWAMAAAAAEASwRgAAAAAgCrBGAAAAACAJIIxAAAAAABVgjEAAAAAAEkEYwAAAAAAqgRjAAAAAACSCMYAAAAAAFQJxgAAAAAAJBGMAQAAAACoEowBAAAAAEgiGAMAAAAAUCUYAwAAAACQRDAGAAAAAKBKMAYAAAAAIIlgDAAAAABAlWAMAAAAAEASwRgAAAAAgCrBGAAAAACAJIIxAAAAAABVgjEAAAAAAEkEYwAAAAAAqgRjAAAAAACSCMYAAAAAAFQJxgAAAAAAJBGMAQAAAACoEowBAAAAAEgiGAMAAAAAUCUYAwAAAACQRDAGAAAAAKBKMAYAAAAAIIlgDAAAAABAlWAMAAAAAEASwRgAAAAAgCrBGAAAAACAJIIxAAAAAABVgjEAAAAAAEmSuqIHAAADr1wu5+mnn06SjB8/PvX19QUvAgAAYCjyDmMAGKFWr16dOXPmZNq0aRk3blwmT56cyZMnZ9y4cZk2bVrmzJmT7u7uomcCAAAwhAjGADDC9PT0ZMaMGTnssMPS3t6erq6u9PX1bb6/r68vXV1daW9vz5QpUzJjxoz09PQUuBgAAIChQjAGgBGiUqlkyZIlmTp1ajo7O7f7eZ2dnZk6dWqWLFmSSqUygAsBAAAY6gRjABgBKpVKZs+enQULFqRcLtf8/HK5nAULFmT27NmiMQAAwCg2ooPxI488kn/6p3/K8ccfn3333Te77rprXv7yl+etb31rvvOd7xQ9DwD6zdKlS9PR0bHT53R0dGTp0qX9sAgAAIDhaEQH4/b29sydOzf3339/jj/++HzoQx/KUUcdla997Wt57Wtfm3//938veiIA7LSenp4sXLiw385buHChaxoDAACMUnVFDxhIRxxxRG699dYcffTRW9ze2dmZY489Nu9///tz8sknp6GhoaCFALDz2tradugyFC+kXC6nra0tK1eu7LczAQAAGB5G9DuM//Iv//J5sThJWltb8/rXvz6/+tWv8oMf/KCAZQDQP1avXl3TB9xtr87OznR3d/f7uQAAAAxtIzoYb0t9fX2SpK5uRL/JGoARbvny5cPybAAAAIamURmMH3roodx4443Zc889c+ihhxY9BwB22KpVq4bl2QAAAAxNo+7tteVyOaeffno2btyYpUuXZpdddil6Uk0qlUo2bNhQ9IxB15/X5hxtyuVy1q9fX/SMQfHc73O0fM9Dmddj4JXL5QH9cLqenp6sXbvW38YBAAB2WGNjY0qlUtEzqMGo+h3gpk2bcuaZZ2blypWZNWtWTj/99KIn1WzDhg0ZN25c0TMYRpYtW5Zly5YVPWPQNTU1FT2B5/B6DE8bN27MpEmTip4BAAAMY+vWrcvYsWOLnkENRs0lKTZt2pSZM2fmX//1X/M3f/M3+dznPlf0JAAAAACAIWVUvMN406ZNOeuss/L5z38+73jHO7JixYqMGTM8W3ljY2PWrVtX9IxBN3fu3FH5Ltn+MGvWrFx00UVFzxgU69ev3/xO1t7eXn+CWTCvx8Arl8tpampKX1/fgJzf0NCQ3t5el6QAAAB2WGNjY9ETqNGI/x3gc2PxqaeemquvvnrYXbf4uUql0qiMLvX19UVPGLbq6+tH5c+ZsWPHjsrve6jyegyc5ubmdHV1DdjZEydOHJCzAQAAGJqG59tst9PvL0Px+c9/Pm9729vyhS98YVjHYgD4Q9OnTx+WZwMAADA0jeh3GC9atChXXXVVxo0blz/+4z/OJz/5yec95uSTT86UKVMGfxwA9IOZM2emvb19wM4GAABgdBnRwfiBBx5I8rtPYzz//PO3+pj9999fMAZg2JoyZUpaW1vT2dnZr+e2trampaWlX88EAABg6BvRl6RYsWJFKpXKNv8588wzi54JADvl0ksv7ddrvdfX16ejo6PfzgMAAGD4GNHBGABGg+bm5ixatKjfzlu0aFEOPfTQfjsPAACA4UMwBoARYN68eTn33HN3+py2trbMmzevHxYBAAAwHAnGADAClEqltLe3Z/HixTt0eYr6+vosXrw4l1xySUql0gAsBAAAYDgQjAFghCiVSpk/f366urrS2tq63c9rbW3NXXfdlfnz54vFAAAAo1xd0QMAgP7V3NyclStXpru7O8uXL8+qVavS3d2dvr6+JElDQ0Oam5szffr0zJw5My0tLQUvBgAAYKgQjAFghGppacnFF1+cJFm7dm0mTZqUJOnt7c3EiRMLXAYAAMBQ5ZIUADAK1NXVbfXHAAAA8FyCMQAAAAAASQRjAAAAAACqBGMAAAAAAJIIxgAAAAAAVAnGAAAAAAAkEYwBAAAAAKgSjAEAAAAASCIYAwAAAABQJRgDAAAAAJBEMAYAAAAAoEowBgAAAAAgiWAMAAAAAECVYAwAAAAAQBLBGAAAAACAKsEYAAAAAIAkgjEAAAAAAFWCMQAAAAAASQRjAAAAAACqBGMAAAAAAJIIxgAAAAAAVAnGAAAAAAAkEYwBAAAAAKgSjAEAAAAASCIYAwAAAABQJRgDAAAAAJBEMAYAAAAAoEowBgAAAAAgiWAMAAAAAECVYAwAAAAAQBLBGAAAAACAKsEYAAAAAIAkgjEAAAAAAFWCMQAAAAAASQRjAAAAAACqBGMAAAAAAJIIxgAAAAAAVAnGAAAAAAAkEYwBAAAAAKgSjAEAAAAASCIYAwAAAABQJRgDAAAAAJBEMAYAAAAAoEowBgAAAAAgiWAMAAAAAECVYAwAAAAAQBLBGAAAAACAKsEYAAAAAIAkgjEAAAAAAFWCMQAAAAAASQRjAAAAAACqBGMAAAAAAJIIxgAAAAAAVAnGAAAAAAAkEYwBAAAAAKgSjAEAAAAASCIYAwAAAABQJRgDAAAAAJBEMAYAAAAAoEowBgAAAAAgiWAMAAAAAECVYAwAAAAAQBLBGAAAAACAKsEYAAAAAIAkgjEAAAAAAFWCMQAAAAAASQRjAAAAAACqBGMAAAAAAJIIxgAAAAAAVAnGAAAAAAAkEYwBAAAAAKgSjAEAAAAASCIYAwAAAABQJRgDAAAAAJAkqSt6AADAaFMul/P0008nScaPH5/6+vqCFwEAAPyOdxgDAAyC1atXZ86cOZk2bVrGjRuXyZMnZ/LkyRk3blymTZuWOXPmpLu7u+iZAADAKCcYAwAMoJ6ensyYMSOHHXZY2tvb09XVlb6+vs339/X1paurK+3t7ZkyZUpmzJiRnp6eAhcDAACjmWAMADAAKpVKlixZkqlTp6azs3O7n9fZ2ZmpU6dmyZIlqVQqA7gQAADg+QRjAIB+VqlUMnv27CxYsCDlcrnm55fL5SxYsCCzZ88WjQEAgEE1ooPxb3/723zwgx/MjBkzstdee+WP/uiP8vKXvzxHHnlkrrzyyh36DRwAwItZunRpOjo6dvqcjo6OLF26tB8WAQAAbJ8RHYzXrVuXz372symVSvmLv/iLfPCDH8wpp5ySRx55JDNnzsyJJ56YTZs2FT0TABhBenp6snDhwn47b+HCha5pDAAADJq6ogcMpJe+9KVZu3Ztdt111y1uf+aZZ3LcccflhhtuyHXXXZe/+Iu/KGghADDStLW19evfYiqXy2lra8vKlSv77UwAAIAXMqLfYTxmzJjnxeIkqauryymnnJIkWbNmzWDPAgBGqNWrV9f0AXfbq7OzM93d3f1+LgAAwB8a0cH4hWzatCnf+ta3kiSHHHJIwWsAgJFi+fLlw/JsAACA3xvRl6T4vb6+vnzqU59KpVLJE088kZtuuik//vGPc9ZZZ+XYY48teh4AMEKsWrVqWJ4NAADwe6MmGH/iE5/Y/HWpVMqHP/zhLF68uMBVO6ZSqWTDhg1Fzxh0/XktyNGmXC5n/fr1Rc8YFM/9PkfL9zyUeT2GFq/HwCuXywP64XQ9PT1Zu3Zt6upGxS/fAAAYIRobG1MqlYqeQQ1Gxe84xo0bl0qlkk2bNuXRRx/N//t//y8f/ehHs2rVqnzzm9/MhAkTip643TZs2JBx48YVPYNhZNmyZVm2bFnRMwZdU1NT0RN4Dq/H0OL1GJ42btyYSZMmFT0DAABqsm7duowdO7boGdRgVF3DeMyYMdl7773z/ve/P5dddlnuuOOOnH/++UXPAgAAAAAYEkbFO4y35vjjj0+S3HrrrcUOqVFjY2PWrVtX9IxBN3fu3FH5Ltn+MGvWrFx00UVFzxgU69ev3/zOyd7eXn+CWTCvx9Di9Rh45XI5TU1N6evrG5DzGxoa0tvb65IUAAAMK42NjUVPoEaj9nccjz76aJKkvr6+4CW1KZVKo/I3+cPtdRpK6uvrR+XPmbFjx47K73uo8noMLV6PgdPc3Jyurq4BO3vixIkDcjYAAMDvjehLUvzoRz/a6gfEbdiwIR/84AeTJCeccMJgzwIARqjp06cPy7MBAAB+b0S/w/iaa67Jpz/96Rx11FHZf//9M2HChDzyyCO57rrr8sQTT6S1tTVz584teiYAMELMnDkz7e3tA3Y2AADAQBvRwfjEE0/Mo48+mjvvvDOrVq3KunXrMnHixDQ3N+e0007LzJkzXQcQAOg3U6ZMSWtrazo7O/v13NbW1rS0tPTrmQAAAFszomvp1KlTM3Xq1KJnAACjyKWXXpqpU6emXC73y3n19fXp6Ojol7MAAABezIi+hjEAwGBrbm7OokWL+u28RYsW5dBDD+238wAAALZFMAYA6Gfz5s3Lueeeu9PntLW1Zd68ef2wCAAAYPsIxgAA/axUKqW9vT2LFy9OfX19zc+vr6/P4sWLc8kll6RUKg3AQgAAgK0TjAEABkCpVMr8+fPT1dWV1tbW7X5ea2tr7rrrrsyfP18sBgAABt2I/tA7AICiNTc3Z+XKlenu7s7y5cuzatWqdHd3p6+vL0nS0NCQ5ubmTJ8+PTNnzkxLS0vBiwEAgNFMMAYAGAQtLS25+OKLkyRr167NpEmTkiS9vb2ZOHFigcsAAAD+fy5JAQAwyOrq6rb6YwAAgKIJxgAAAAAAJBGMAQAAAACoEowBAAAAAEgiGAMAAAAAUCUYAwAAAACQRDAGAAAAAKBKMAYAAAAAIIlgDAAAAABAlWAMAAAAAEASwRgAAAAAgCrBGAAAAACAJIIxAAAAAABVgjEAAAAAAEkEYwAAAAAAqgRjAAAAAACSCMYAAAAAAFQJxgAAAAAAJBGMAQAAAACoEowBAAAAAEgiGAMAAAAAUCUYAwAAAACQRDAGAAAAAKBKMAYAAAAAIIlgDAAAAABAlWAMAAAAAEASwRgAAAAAgCrBGAAAAACAJIIxAAAAAABVgjEAAAAAAEkEYwAAAAAAqgRjAAAAAACSCMYAAAAAAFQJxgAAAAAAJBGMAQAAAACoqit6AAwnixYtetHHjBkzJhMmTMif/Mmf5HWve10aGhoGYRkAAAAA7DzBGGpw3nnnpVQqbf66Uqls/vEf3l4qlfKSl7wkn/70p3PGGWcM6k4AAAAA2BEuSQE1uOWWW3LiiSemoaEhs2bNylVXXZVvfetbueqqqzJr1qw0NDTkzW9+c770pS9lwYIFKZfLmTlzZm688caipwMAAADAi/IOY6jBvffem9tuuy133313/vRP/3SL+04//fR84AMfyKtf/eqcdNJJ+eQnP5l3vvOdOfzww3PhhRfmDW94Q0GrAQAAAGD7eIcx1ODiiy/Oqaee+rxY/Ht/+qd/mlNPPTUXXXRRkuSVr3xl3vzmN+e73/3uYM4EAAAAgB0iGEMN1qxZk5e+9KXbfMzkyZNz3333bf76oIMOyrp16wZ6GgAAAADsNMEYarD77rvnuuuu2+LD7p6rUqnkuuuuy+TJkzff9qtf/SoTJ04crIkAAAAAsMMEY6jBaaedlp6enpx00knp6enZ4r6enp685S1vyQ9+8IO84x3v2Hz7d7/73fzZn/3ZYE8FAAAAgJr50DuowSc+8Yl0dXXlG9/4Rr75zW9m7Nix2X333fP4449n/fr1qVQqmTFjRj7xiU8kSX75y19m//33z9vf/vaClwMAAADAi/MOY6jBbrvtlhtvvDHLli3LjBkzUl9fn4ceeij19fU5+uijs2zZstx8883ZbbfdkiQvf/nL85WvfGWLdxwDAAAAwFDlHcZQozFjxuTd73533v3udxc9BQAAAAD6lXcYAwAAAACQxDuMYYc888wz+clPfpKnnnoqzz777FYfM2PGjEFeBQAAAAA7RzCGGlQqlSxcuDDt7e15+umnt/nYFwrJAAAAADBUCcZQg7//+7/P+eefn0mTJuWMM87I3nvvnbo6/xkBAAAAMDIoXVCD5cuXZ7/99ktXV1cmT55c9BwAAAAA6Fc+9A5q8Mtf/jInn3yyWAwAAADAiCQYQw0OOOCA/PrXvy56BgAAAAAMCMEYavD+978/X//61/PYY48VPQUAAAAA+p1rGEMN3vKWt6SzszOvfe1rs3Dhwhx++OGZMGHCVh+77777DvI6AAAAANg5gjHU4IADDkipVEqlUslZZ531go8rlUp55plnBnEZAAAAAOw8wRhqcMYZZ6RUKhU9AwAAAAAGhGAMNVixYkXREwAAAABgwPjQOwAAAAAAkgjGAAAAAABUuSQFbMMxxxyTUqmUq666KnvvvXeOOeaY7XpeqVTKTTfdNMDrAAAAAKB/CcawDbfeemtKpVI2bNiw+evt4YPxAAAAABiOBGPYhk2bNm3zawAAAAAYSVzDGAAAAACAJIIxAAAAAABVLkkB2/D5z39+h597xhln9OMSAAAAABh4gjFsw5lnnrnFB9hVKpUX/UC73z9GMAYAAABguBGMYRuuvPLK5932pS99Kd/4xjdy7LHHprW1NU1NTent7c3KlStz880358QTT8xb3/rWAtYCAAAAwM4RjGEb3vWud23x9Ve/+tX813/9V66//vocd9xxz3v8DTfckJNOOinvec97BmsiAAAAAPQbH3oHNfjUpz6Vt7/97VuNxUly/PHH521ve1s++clPDvIyAAAAANh5gjHU4J577sk+++yzzcfss88+ueeeewZpEQAAAAD0H8EYajB+/PisXLlym49ZuXJlxo8fP0iLAAAAAKD/CMZQg5NPPjl33nln3v/+9+exxx7b4r7HHnss73vf+7Jq1aqccsopBS0EAAAAgB3nQ++gBosXL86dd96Zf/7nf86KFSty8MEHZ4899shjjz2WNWvWZOPGjTnkkEOyePHioqcCAAAAQM28wxhq8JKXvCTf+c53snDhwuy111655557csstt+See+7JXnvtlYULF+bb3/52Jk2aVPRUAGA7lcvlPPnkk3nyySdTLpeLngMAAIXyDmOo0W677Zbzzjsv5513Xp5++un8+te/zoQJE1y3GACGkdWrV2f58uVZtWpVenp60tfXlyTZdddd09zcnOnTp+fd7353WlpaCl4KAACDSzCGnTB+/HihGACGkZ6enrS1taWzs3Or9/f19aWrqytdXV1pb29Pa2trLr300jQ3Nw/yUgAAKIZLUgAAMOJVKpUsWbIkU6dOfcFYvDWdnZ2ZOnVqlixZkkqlMoALAQBgaPAOY9iGMWPGpFQq1fy8UqmUZ555ZgAWAQC1qlQqmT17djo6Onbo+eVyOQsWLMjPf/7ztLe379CvDQAAYLgYlcF46dKlmT9/fpJk1apVec1rXlPwIoaqGTNmPO83hb/61a/S09OTXXbZJfvss0+amprS29ubhx9+OM8++2yam5vzkpe8pKDFAMAfWrp06Q7H4ufq6OjI3nvvvfnXkQAAMBKNumD8wx/+MB//+MczduzYrF+/vug5DHG33nrrFl///Oc/z5FHHpl3vvOd+dSnPpV99913830PPfRQFixYkDvuuCNf//rXB3kpALA1PT09WbhwYb+dt3DhwpxwwgmuaQwAwIg1qq5hXC6X8653vStTpkzJKaecUvQchqEPf/jD2XPPPfOFL3xhi1icJPvuu2/+5V/+JS9/+cvzd3/3dwUtBACeq62tLeVyud/OK5fLaWtr67fzAABgqBlVwfj888/PPffck+XLl2eXXXYpeg7D0I033phjjz12m4855phjcuONNw7SIgDghaxevbqmD7jbXp2dnenu7u73cwEAYCgYNcH47rvvzvnnn5+Pf/zjeeUrX1n0HIap3/72t/nFL36xzcc8+uij+c1vfjNIiwCAF7J8+fJheTYAABRpVATjjRs35owzzsiUKVPykY98pOg5DGOvetWr8sUvfjGrVq3a6v133nln/v3f/z3Tpk0b5GUAwB96of+9HupnAwBAkUbFh94tXLgw9957b+66665hfymKSqWSDRs2FD1j0PXntQd3xvnnn59jjz02ra2tefOb35yjjjoqe+yxRx577LF0dnbm61//eurq6vLJT36y6KmblcvlUfMBj8/9PkfL9zyUeT2GFq/H0OL1GHjlcjk9PT0Ddn5PT0/Wrl2burpR8ctpAIAd1tjYmFKpVPQMajDif4W7atWqXHDBBTnvvPNyyCGHFD1np23YsCHjxo0resaoddRRR+Wb3/xmzj777Hzta1/L1772tZRKpVQqlSTJAQcckMsuuyxHHnlkwUv/f8uWLcuyZcuKnjHompqaip7Ac3g9hhavx9Di9RieNm7cmEmTJhU9AwBgyFu3bl3Gjh1b9AxqMKKD8TPPPJN3vetdaW5uzvz584uewwhx7LHHZs2aNbn99tvT3d2dtWvXZuLEiWlpaclRRx3lT80AAAAAGLZGdDBet25d7r333iTJrrvuutXHTJ8+PUnyla98JSeffPJgTdthjY2NWbduXdEzBt3cuXOH1LtkS6VSWltb09raWvSUFzVr1qxcdNFFRc8YFOvXr9/8Tr3e3l5/glkwr8fQ4vUYWrweA69cLqepqSl9fX0Dcn5DQ0N6e3tdkgIA4EU0NjYWPYEajehf4TY0NOTd7373Vu9buXJl7r333px00knZfffds//++w/uuB1UKpVG5W8q6+vri57wPD/60Y/y4x//OOvXr8/pp59e9JwXVF9fPyp/zowdO3ZUft9DlddjaPF6DC1ej4HT3Nycrq6uATt74sSJA3I2AAAUaUQH49122y2XX375Vu8788wzc++992bBggV5zWteM8jLGM6+973vZdasWfnBD36w+bbfB+OVK1fmTW96U774xS/mpJNOKmoiAJDf/U2ygQrGv/9bagAAMNKMKXoADCf33HNPjjnmmPzsZz/L3Llz8+d//udb3N/a2pqXvexlufbaawtaCAD83syZM4fl2QAAUCTBGGrw8Y9/PEly11135YILLsi0adO2uL9UKmX69On53ve+V8Q8AOA5pkyZMiCfN9Da2pqWlpZ+PxcAAIaCURuMV6xYkUql4nIU1OS2227LW9/61hx88MEv+Jh99903v/jFLwZxFQDwQi699NJ+/SyE+vr6dHR09Nt5AAAw1IzaYAw74umnn84ee+yxzcf85je/ybPPPjtIiwCAbWlubs6iRYv67bxFixbl0EMP7bfzAABgqBGMoQb77LPPFh92tzV33313DjrooEFaBAC8mHnz5uXcc8/d6XPa2toyb968flgEAABDl2AMNTjxxBNzww035MYbb9zq/ddcc02+/e1v5+STTx7cYQDACyqVSmlvb8/ixYt36PIU9fX1Wbx4cS655JKUSqUBWAgAAEOHYAw1+OhHP5q99torJ5xwQmbNmpWurq4kyWc+85mcfvrpeec735n9998/H/zgBwteCgA8V6lUyvz589PV1VXTB+G1trbmrrvuyvz588ViAABGhbqiB8Bwsvvuu+e2227L6aefniuuuGLz7W1tbUmSV7/61fm3f/u3TJw4saiJAMA2NDc3Z+XKlenu7s7y5cuzatWqdHd3p6+vL0nS0NCQ5ubmTJ8+PTNnzkxLS0vBiwEAYHAJxlCjAw88MHfccUdWr16db3/723nyySczYcKEvPrVr860adOKngcAbIeWlpZcfPHFSZK1a9dm0qRJSZLe3l5/8AsAwKgmGMMOmjJlSqZMmVL0DABgJ9XV1W31xwAAMBr5FTHsoCeeeCLd3d1Zu3ZtJk6cmJaWlkyePLnoWQAAAACwwwRjqNEDDzyQv/3bv803vvGNVCqVzbeXSqWceOKJ+ad/+qfsv//+xQ0EAAAAgB0kGEMN7rvvvhx55JF57LHH8opXvCJHHnlkmpqa0tvbmzvvvDP/+Z//mW9/+9u58847c+CBBxY9FwAAAABqIhhDDebNm5fHH388n/vc5zJr1qyUSqXN91UqlVx22WU555xzMm/evFx77bUFLgUAAACA2gnGUIObbropJ510Us4+++zn3VcqlfLe97433/zmN3PjjTcWsA4AAAAAds6YogfAcPLss8/mf//v/73NxxxyyCF59tlnB2kRAAAAAPQfwRhqcPjhh+eee+7Z5mPuueeeTJ06dZAWAQAAAED/EYyhBueff36uu+66XH755Vu9/7LLLsv111+fT37yk4O8DAAAAAB2nmsYwzYsWrToebe9/vWvz3vf+95ceOGFOfLII9PU1JTe3t7ccccd+elPf5o3vvGNuemmm/La1762gMUAAAAAsOMEY9iG88477wXv+8lPfpKf/OQnz7v9W9/6Vq6//vp87GMfG8BlAAAAAND/BGPYhltuuaXoCQAAAAAwaARj2Iajjz666AkAAAAAMGh86B0AAAAAAEm8wxh2yOOPP54f/ehHefTRR1Mul7f6mDPOOGOQVwEAAADAzhGMoQa/+c1vMnv27Fx99dV55plntvqYSqWSUqkkGAMAAAAw7AjGUIM5c+Zk+fLlaW5uzl/91V9lzz33TF2d/4wAAAAAGBmULqjBl7/85UydOjWrVq3KLrvsUvQcAAAAAOhXPvQOavDss8/mda97nVgMAAAAwIgkGEMNpk2blnvvvbfoGQAAAAAwIARjqMHf//3f54YbbsjXv/71oqcAAAAAQL9zDWOowfTp03PDDTfkpJNOyuGHH56WlpZMmDDheY8rlUr52Mc+VsBCAAAAANhxgjHU4IknnsiCBQvyq1/9KjfddFNuuummrT5OMAYAAABgOBKMoQazZ8/O7bffnhNOOCGnnXZa9txzz9TV+c8IAAAAgJFB6YIafOtb38rrXvc61zAGAAAAYETyoXdQg0qlkqlTpxY9AwAAAAAGhGAMNTjyyCPT3d1d9AwAAAAAGBCCMdTgggsuyPe+971ceumlRU8BAAAAgH7nGsZQg3/4h39Ic3Nz/vZv/zaXXHJJmpubM2HChOc9rlQq5YorrihgIQAAAADsOMEYarBixYrNP16zZk3WrFmz1ccJxgAAAAAMR4Ix1OBnP/tZ0RMAAAAAYMAIxlCD/fbbr+gJAAAAADBgfOgdAAAAAABJBGN4Ucccc0w+//nPb3Hbd77znVxyySVbffzSpUszefLkwZgGAAAAAP1KMIYXceutt+aBBx7Y4rZvfetbmTt37lYf/9vf/jZPPfXUwA8DAAAAgH4mGAMAAAAAkEQwBgAAAACgSjAGAAAAACCJYAwAAAAAQJVgDAAAAABAkqSu6AEwHHz961/PL3/5y81fd3V1JUnOOeec5z32e9/73qDtAgAAAID+JBjDdujq6tociZ/rc5/73FYfXyqVBnoSAAAAAPQ7wRhexC233FL0BAAAAAAYFIIxvIijjz666AkAAAAAMCh86B0AAAAAAEkEY9ghX/nKV/L2t789zc3NOfjggzff/uMf/zj/8A//kEceeaTAdQAAAACwY1ySAmqwadOmvOMd78iXvvSlJMluu+2W3/zmN5vvf8lLXpL/83/+T5599tksWLCgqJkAAAAAsEO8wxhqcNFFF+Xaa6/Ne9/73vzqV7/Khz/84S3ub2pqSmtra77xjW8UtBAAAAAAdpxgDDVYsWJFpk2bls985jOZMGFCSqXS8x5z8MEH52c/+1kB6wAAAABg5wjGUIM1a9aktbV1m4+ZPHlynnjiiUFaBAAAAAD9RzCGGuy2225Zu3btNh/z4IMPZtKkSYMzCAAAAAD6kWAMNTjssMNy/fXX57e//e1W73/yySfzrW99K695zWsGeRkAAAAA7DzBGGowZ86c/PznP89b3/rW/PznP9/ivvvuuy+nnHJK1q5dmzlz5hS0EAAAAAB2XF3RA2A4ectb3pJ58+Zl6dKl2W+//TJ27NgkyR577JEnnngilUolH/vYx3LMMccUvBQAAAAAaucdxlCjxYsX5/rrr8+JJ56YxsbG7LLLLtm0aVPe9KY35brrrssnPvGJoicCAAAAwA7xDmPYAccdd1yOO+64omcAAAAAQL/yDmMAAAAAAJJ4hzFs00MPPbTDz9133337cQkAAAAADDzBGLZh//33T6lUqvl5pVIpzzzzzAAsAgAAAICBIxjDNpxxxhnPC8b3339/Ojs7M2nSpEyZMiVNTU3p7e3N6tWr89RTT6W1tTUHHnhgQYsBAAAAYMcJxrANK1as2OLre+65J0ceeWQ++tGPZsGCBRk7duzm+9avX5/zzz8/n/3sZ/PZz352kJcCAAAAwM7zoXdQg4985CM54ogj8slPfnKLWJwkY8eOzac+9alMnTo18+bNK2ghAAAAAOw4wRhqcMcdd+SII47Y5mOOOOKIdHZ2DtIiAAAAAOg/gjHUYNOmTVmzZs02H3PvvfemUqkM0iIAAAAA6D+CMdRgxowZ+fKXv5wvfvGLW73/3/7t3/If//EfmTFjxiAvAwAAAICd50PvoAb/8A//kM7Ozvz1X/91li5dmqOOOip77LFHHnvssdx+++3p6enJ+PHjs3Tp0qKnAgAAAEDNBGOowStf+crccccdaWtry8qVK9Pd3b3F/TNmzEhHR0de+cpXFrQQAAAAAHacYAw1OuSQQ3Lrrbfm4YcfTnd3d9auXZuJEyempaUl++yzT9HzAAAAAGCHCcawg/bZZx+BGAAAAIARxYfeAQAAAACQxDuMoSbHHHPMdj2uVCrlpptuGuA1AAAAANC/BGOowa233rrN+0ulUiqVSkql0uAMAgAAAIB+5JIUUINNmzZt9Z+nnnoqN998c1796lfnr/7qr9LX11f0VAAAAAComWAM/WDChAl53etel+uvvz7f/e53c/755xc9CQAAAABqJhhDPxo/fnz+/M//PFdeeWXRUwAAhqVyuZwnn3wyTz75ZMrlctFzAABGHcEY+tmYMWPyi1/8ougZAADDxurVqzNnzpxMmzYt48aNy+TJkzN58uSMGzcu06ZNy5w5c9Ld3V30TACAUUEwhn50//3359prr83+++9f9BQAgCGvp6cnM2bMyGGHHZb29vZ0dXVt8VkQfX196erqSnt7e6ZMmZIZM2akp6enwMUAACNfXdEDYDiZOXPmVm9/5pln8sgjj+T2229PuVzOokWLBnkZAMDwUalUsnTp0ixcuLCmy050dnZm6tSpWbRoUebNm5dSqTSAKwEARifBGGqwYsWKbd7/J3/yJ/nQhz6U97znPYMzCABgmKlUKpk9e3Y6Ojp26PnlcjkLFizIz3/+87S3t4vGAAD9bMQH4/333z8PPvjgVu87+uijc+uttw7uIIa1n/3sZ1u9fcyYMZk0aVLGjx8/yIsAAIaXpUuX7nAsfq6Ojo7svffemT9/fj+sAgDg90Z8ME6SiRMn5gMf+MDzbnedWWq13377FT0BAGDY6unpycKFC/vtvIULF+aEE05Ic3Nzv50JADDajYpgPGnSpJx33nlFz2AEOOaYY3LmmWfmjDPOeMHHfOELX8jy5ctz8803D+IyAIChr62traZrFr+Ycrmctra2rFy5st/OBAAY7cYUPQCGk1tvvTUPPPDANh/z4IMP5rbbbhucQQAAw8Tq1avT2dnZ7+d2dnamu7u7388FABitRsU7jDdu3JgVK1bk0UcfzYQJEzJt2rS8+tWvLnoWI9T69etTX19f9AwAgCFl+fLlA3r2xRdfPGDnAwCMJqMiGP/yl7/MWWedtcVt06ZNy7/927/loIMOKmgVw8VDDz20xddPPfXU825LkmeffTYPP/xwvvzlL7s+NgDAH1i1atWwPBsAYLQZ8cH4rLPOSmtraw455JCMGzcuP/3pT/PpT386V199dY499tj84Ac/yPjx44ueud0qlUo2bNhQ9IxB15/XuqvV/vvvn1KplCQplUq5+OKLt/kOlkqlkn/8x38crHkvqlwuZ/369UXPGBTP/T5Hy/c8lHk9hhavx9Di9RhavB4Dr1wup6enZ8DO7+npydq1a1NXN+J/ewMAw05jY+PmrsLwUKpUKpWiRxThjDPOyNVXX50LL7wwH/zgB4ues93Wr1+fcePGFT2jcOecc046OjoG5f/WmWeemVKplEqlks9//vNpaWnJlClTnve4XXbZJS996UtzzDHH5E1vetOgbNuac889N5/5zGcK+78PAAAA8Hvr1q3L2LFji55BDUbtH8G/973vzdVXX5077rhjWAVjBt+KFSs2//i2227LWWedlTlz5hQ3CAAAAAAGyKgNxi972cuSDL+/dtjY2Jh169YVPWPQzZ07N8uWLSt6Rn72s58VPaFms2bNykUXXVT0jEGxfv36NDU1JUl6e3v9CWbBvB5Di9djaPF6DC1ej4FXLpfT1NSUvr6+ATm/oaEhvb29LkkBAENQY2Nj0ROo0aj9FdV3vvOdJBl2H05WKpVG5W9i6uvri54wbNXX14/KnzNjx44dld/3UOX1GFq8HkOL12No8XoMnObm5nR1dQ3Y2RMnThyQswEARpsRHYx//OMfZ999933en2T8+Mc/zrx585Ik73znO4uYxjBxzDHHpFQq5aqrrsree++dY445ZrueVyqVctNNNw3wOgCA4WP69OkDFoynT58+IOcCAIxGIzoYf/GLX8ynP/3pzJgxI/vtt1/Gjh2bn/70p/nmN7+ZcrmcBQsWZMaMGUXPZAi79dZbUyqVsmHDhs1fbw+f/gkAsKWZM2emvb19wM4GAKB/jOhg/PrXvz7//d//ne9///vp7OzMhg0b8rKXvSwnnHBCzjnnnBx//PFFT2SI27Rp0za/BgBg+0yZMiWtra3p7Ozs13NbW1vT0tLSr2cCAIxmIzoYH3300Tn66KOLngEAACS59NJLM3Xq1JTL5X45r76+Ph0dHf1yFgAAvzOm6AEAAMDo0NzcnEWLFvXbeYsWLcqhhx7ab+cBADDC32EMO2vlypU7/FzXxwYAeL558+bl5z//+U6/M7itrW3zB1kDANB/BGPYhte97nU7/AF2zz77bD+vAQAY/kqlUtrb27P33ntn4cKFNV+eor6+PosWLcq8efN80DAAwAAQjGEbFi5c6DciAAD9rFQqZf78+TnhhBPS1ta23R+E19ramo6ODpehAAAYQIIxbMN5551X9AQAgBGrubk5K1euTHd3d5YvX55Vq1alu7s7fX19SZKGhoY0Nzdn+vTpmTlzZlpaWgpeDAAw8gnGAABAoVpaWnLxxRcnSdauXZtJkyYlSXp7ezNx4sQClwEAjD6CMeyAjRs35pvf/Ga+//3vZ+3atZk4cWIOO+ywnHDCCWloaCh6HgDAsFVXV7fVHwMAMDj8Cgxq9J//+Z85++yz8/jjj6dSqWy+vVQqZY899shll12WN7/5zQUuBAAAAIAdIxhDDW666aa89a1vzS677JKZM2emtbU1TU1N6e3tzcqVK/OFL3whf/mXf5nrr78+xxxzTNFzAQAAAKAmgjHU4OMf/3h222233HnnnTnkkEO2uO+MM87InDlzcuSRR+bjH/+4YAwAAADAsDOm6AEwnHz/+9/Pqaee+rxY/HvNzc15+9vfnrvvvnuQlwEAAADAzhOMoQaNjY3Zfffdt/mYPfbYI42NjYO0CAAAAAD6j2AMNXjDG96QG2+8cZuPufHGG3PccccN0iIAAAAA6D+CMdTgggsuyGOPPZYzzjgjDz/88Bb3Pfzwwzn99NPzP//zP7ngggsKWggAAAAAO86H3kENTj/99LzkJS/Jv/zLv+SLX/xi9t133zQ1NaW3tzcPPfRQnn322TQ3N+dv/uZvtnheqVTKTTfdVNBqAAAAANg+gjHU4NZbb93842eeeSb3339/7r///i0e093d/bznlUqlgZ4GAAAAADtNMIYabNq0qegJAAAAADBgXMMYAAAAAIAkgjEAAAAAAFUuSQE1qlQq+drXvpbu7u48+uijKZfLz3tMqVTKFVdcUcA6AAAAANhxgjHUYM2aNTnxxBNz7733plKpvODjBGMAAAAAhiPBGGpw7rnn5qc//Wne//735x3veEf23HPP1NX5zwgAAACAkUHpghp0dnbmpJNOSkdHR9FTAAAAAKDf+dA7qMH48eNz8MEHFz0DAAAAAAaEYAw1OO6443LnnXcWPQMAAAAABoRgDDX4x3/8xzz66KP5u7/7u/z2t78teg4AAAAA9CvXMIYa7Lnnnrn++uszffr0XHbZZXnFK16RCRMmPO9xpVIpN910UwELAQAAAGDHCcZQg+9///s57rjj8tRTTyVJ7r777q0+rlQqDeIqAAAAAOgfLkkBNfjABz6Qp556KkuXLs1DDz2UcrmcTZs2Pe+fZ599tuipAAAAAFAz7zCGGtx111059dRT83d/93dFTwEAAACAfucdxlCDCRMmpKmpqegZAAAAADAgBGOowVve8pbcfPPN2bRpU9FTAAAAAKDfCcZQg6VLl6ahoSF//dd/nUceeaToOQAAAADQr1zDGGowZcqU9PX1paurK9dcc01e8pKXZMKECc97XKlUyn333VfAQgAAAADYcYIx1GDTpk2pr6/Pvvvuu/m2SqXyvMdt7TYAAAAAGOoEY6jBAw88sF2P27hx48AOAQAAAIAB4BrG0I/uvvvunHvuudlrr72KngIAAAAANfMOY9hJTz31VL7whS/kiiuuSE9PTyqVSnbbbbeiZwEAAABAzQRj2EE33nhjrrjiinzta1/Lxo0bU6lUMn369Jx11lk59dRTi54HAAAAADUTjKEGDz/8cK688spceeWVeeihh1KpVPK//tf/yiOPPJIzzzwzy5cvL3oiAAAAAOwwwRheRLlczle/+tVcccUVuemmm/Lss89m7Nix+eu//uucccYZOeaYY1JXV5e6Ov85AQAAADC8KVzwIvbaa688+eSTKZVKef3rX58zzjgjf/mXf5mxY8cWPQ0AAAAA+pVgDC/iiSeeyJgxYzJ37tx85CMfye677170JAAAAAAYEGOKHgBD3Zlnnpnddtstn/70p7P33nvnpJNOyrXXXpu+vr6ipwEAAABAvxKM4UUsX748v/jFL/LP//zPOfzww/P1r389p512WpqamvLe9743t99+e9ETAQAAAKBfCMawHcaNG5f3vOc9WbVqVe6555584AMfyK677pply5bl6KOPTqlUyk9+8pM8+OCDRU8FAAAAgB0mGEON/uzP/iwXXnhhHnnkkVxzzTU5/vjjUyqV0tnZmYMOOijHHntsrr766qJnAgAAAEDNBGPYQXV1dfmrv/qrXHfddXnggQfyiU98Ivvtt19uueWWnHnmmUXPAwAAAICaCcbQD/bee+987GMfy3333Zf/+q//ymmnnVb0JAAAAACoWV3RA2CkOfbYY3PssccWPQMAAAAAauYdxgAAAAAAJBGMAQAAAACoEowBAAAAAEgiGAMAAAAAUCUYAwAAAACQRDAGAAAAAKBKMAYAAAAAIIlgDAAAAABAlWAMAAAAAEASwRgAAAAAgCrBGAAAAACAJIIxAAAAAABVgjEAAAAAAEkEYwAAAAAAqgRjAAAAAACSCMYAAAAAAFQJxgAAAAAAJBGMAQAAAACoEowBAAAAAEgiGAMAAAAAUCUYAwAAAACQRDAGAAAAAKBKMAYAAAAAIIlgDAAAAABAlWAMAAAAAEASwRgAAAAAgCrBGAAAAACAJIIxAAAAAABVgjEAAAAAAEkEYwAAAAAAquqKHgAAAMDQVC6X8/TTTydJxo8fn/r6+oIXAQADzTuMAQAA2Gz16tWZM2dOpk2blnHjxmXy5MmZPHlyxo0bl2nTpmXOnDnp7u4ueiYAMEAEYwAAANLT05MZM2bksMMOS3t7e7q6utLX17f5/r6+vnR1daW9vT1TpkzJjBkz0tPTU+BiAGAgCMYAAACjWKVSyZIlSzJ16tR0dnZu9/M6OzszderULFmyJJVKZQAXAgCDSTAGAAAYpSqVSmbPnp0FCxakXC7X/PxyuZwFCxZk9uzZojEAjBCjJhh/5StfyXHHHZfJkyfnj/7oj3LAAQfkHe94Rx5++OGipwEAABRi6dKl6ejo2OlzOjo6snTp0n5YBAAUra7oAQOtUqnkfe97Xy677LIcdNBBOe200zJ+/Pg8+uijue222/Lggw9mn332KXomAADAoOrp6cnChQv77byFCxfmhBNOSHNzc7+dCQAMvhEfjC+55JJcdtllOeecc3LJJZdkl1122eL+Z555pqBlAAAAxWlra9uhy1C8kHK5nLa2tqxcubLfzgQABt+IviTFb37zm3ziE5/IgQcemIsvvvh5sThJ6upGfDMHAADYwurVq2v6gLvt1dnZme7u7n4/FwAYPCM6GN9www351a9+lZNPPjnPPvts/uM//iNLlizJ5z73uaxZs6boeQAAAIVYvnz5sDwbABh4I/rttXfddVeSZJdddklzc3N++tOfbr5vzJgxmTt3bi644IKi5gEAABRi1apVw/JsAGDgjehg/NhjjyVJPv3pT+fwww/Pd7/73fzZn/1Zvv/97+fss8/OhRdemIMOOijvf//7C166/SqVSjZs2FD0jEHXn9dWG23K5XLWr19f9IxB8dzvc7R8z0OZ12No8XoMLV6PocXrMbR4PQZeuVxOT0/PgJ3f09OTtWvXuvwfAEmSxsbGlEqlomdQg1KlUqkUPWKgnH322Vm2bFl22223rFmzJnvttdfm+374wx+mpaUlBxxwwLC6PMX69eszbty4omcU7pxzzklHR0fRM4akc889N5/5zGeKngEAAACQdevWZezYsUXPoAYj+hrGEydOTJJMnTp1i1icJIccckgOPPDA3HfffXnqqacKWAcAAAAAMLSM6L8j9Cd/8idJkkmTJm31/t/f/pvf/OYFHzPUNDY2Zt26dUXPGHRz587NsmXLip4xLM2aNSsXXXRR0TMGxfr169PU1JQk6e3t9SeYBfN6DC1ej6HF6zG0eD2GFq/HwCuXy2lqakpfX9+AnN/Q0JDe3l6XpAAgye9aFsPLiP5f8Ne//vVJkv/+7/9+3n3lcjlr1qzJ2LFjs/vuuw/2tB1WKpVG5S+a6+vri54wbNXX14/KnzNjx44dld/3UOX1GFq8HkOL12No8XoMLV6PgdPc3Jyurq4BO/v3f9sTABh+RvQlKQ466KAcf/zxWbNmTS6//PIt7luyZEmeeuqpnHLKKf7kGwAAGFWmT58+LM8GAAbeiC+ln/nMZ/La1742s2bNyle/+tX86Z/+ab7//e/n5ptvzn777Zd//Md/LHoiAADAoJo5c2ba29sH7GwAYPga0e8wTn73LuOurq6ceeaZueuuu3LJJZfk3nvvzbnnnpvvfve7efnLX170RAAAgEE1ZcqUtLa29vu5ra2taWlp6fdzAYDBM+LfYZwk++yzT6688sqiZwAAAAwZl156aaZOnZpyudwv59XX16ejo6NfzgIAijPi32EMAADA8zU3N2fRokX9dt6iRYty6KGH9tt5AEAxBGMAAIBRat68eTn33HN3+py2trbMmzevHxYBAEUTjAEAAEapUqmU9vb2LF68OPX19TU/v76+PosXL84ll1ySUqk0AAsBgMEmGAMAAIxipVIp8+fPT1dXV00fhNfa2pq77ror8+fPF4sBYAQZFR96BwAAwLY1Nzdn5cqV6e7uzvLly7Nq1ap0d3enr68vSdLQ0JDm5uZMnz49M2fOTEtLS8GLAYCBIBgDAACwWUtLSy6++OIkydq1azNp0qQkSW9vbyZOnFjgMgBgMLgkBQAAAFtVV1e31R8DACOXYAwAAAAAQBLBGAAAAACAKsEYAAAAAIAkgjEAAAAAAFWCMQAAAAAASQRjAAAAAACqBGMAAAAAAJIIxgAAAAAAVAnGAAAAAAAkEYwBAAAAAKgSjAEAAAAASCIYAwAAAABQJRgDAAAAAJBEMAYAAAAAoEowBgAAAAAgiWAMAAAAAECVYAwAAAAAQBLBGAAAAACAKsEYAAAAAIAkgjEAAAAAAFWCMQAAAAAASQRjAAAAAACqBGMAAAAAAJIIxgAAAAAAVAnGAAAAAAAkEYwBAAAAAKgSjAEAAAAASCIYAwAAAABQJRgDAAAAAJBEMAYAAAAAoEowBgAAAAAgiWAMAAAAAECVYAwAAAAAQBLBGAAAAACAKsEYAAAAAIAkgjEAAAAAAFWCMQAAAAAASQRjAAAAAACqBGMAAAAAAJIIxgAAAAAAVAnGAAAAAAAkEYwBAAAAAKgSjAEAAAAASCIYAwAAAABQJRgDAAAAAJBEMAYAAAAAoEowBgAAAAAgiWAMAAAAAECVYAwAAAAAQBLBGAAAAACAKsEYAAAAAIAkgjEAAAAAAFWCMQAAAAAASQRjAAAAAACqBGMAAAAAAJIIxgAAAAAAVAnGAAAAAAAkEYwBAAAAAKgSjAEAAAAASCIYAwAAAABQJRgDAAAAAJBEMAYAAAAAoEowBgAAAAAgiWAMAAAAAECVYAwAAAAAQBLBGAAAAACAKsEYAAAAAIAkgjEAAAAAAFWCMQAAAAAASQRjAAAAAACqBGMAAAAAAJIIxgAAAAAAVAnGAAAAAAAkSeqKHgAAAAC8uHK5nKeffjpJMn78+NTX1xe8CICRyDuMAQAAYIhavXp15syZk2nTpmXcuHGZPHlyJk+enHHjxmXatGmZM2dOuru7i54JwAgiGAMAAMAQ09PTkxkzZuSwww5Le3t7urq60tfXt/n+vr6+dHV1pb29PVOmTMmMGTPS09NT4GIARgrBGAAAAIaISqWSJUuWZOrUqens7Nzu53V2dmbq1KlZsmRJKpXKAC4EYKQTjAEAAGAIqFQqmT17dhYsWJByuVzz88vlchYsWJDZs2eLxgDssBEdjFesWJFSqbTNf4499tiiZwIAAECWLl2ajo6OnT6no6MjS5cu7YdFAIxGdUUPGEhTpkzJxz/+8a3e96UvfSn33HNP3vjGNw7yKgAAANhST09PFi5c2G/nLVy4MCeccEKam5v77UwARocRH4ynTJnyvNv7+vpy6aWXpq6uLu9617sGfxgAAAA8R1tb2w5dhuKFlMvltLW1ZeXKlf12JgCjw4i+JMUL+epXv5onnngiJ554YpqamoqeAwAAwCi2evXqmj7gbnt1dnamu7u7388FYGQblcH48ssvT5K85z3vKXgJAAAAo93y5cuH5dkAjEyjLhg/+OCDuemmm7L33nvnTW96U9FzAAAAGOVWrVo1LM8GYGQa0dcw3porr7wymzZtyplnnplddtml6Dk1q1Qq2bBhQ9EzBl1/XstrtCmXy1m/fn3RMwbFc7/P0fI9D2Vej6HF6zG0eD2GFq/H0OL1GFq8HgOvXC6np6dnwM7v6enJ2rVrU1c36n77DwwRjY2NKZVKRc+gBqVKpVIpesRg2bRpUw444IA8/PDDue+++3LAAQcUPalm69evz7hx44qeUbhzzjknHR0dRc8Yks4999x85jOfKXoGAAAAQNatW5exY8cWPYMajKpLUtx444156KGHcswxxwzLWAwAAAAAMJBG1d9JGQkfdtfY2Jh169YVPWPQzZ07N8uWLSt6xrA0a9asXHTRRUXPGBTr169PU1NTkqS3t9efYBbM6zG0eD2GFq/H0OL1GFq8HkOL12PglcvlNDU1pa+vb0DOb2hoSG9vr0tSAIVpbGwsegI1GjX/i/HEE0/ka1/7Wl760pfmlFNOKXrODiuVSqPyF2n19fVFTxi26uvrR+XPmbFjx47K73uo8noMLV6PocXrMbR4PYYWr8fQ4vUYOM3Nzenq6hqwsydOnDggZwMwMo2aS1JcffXV6evry9/8zd+koaGh6DkAAACQJJk+ffqwPBuAkWnUBOMrrrgiyfC+HAUAAAAjz8yZM4fl2QCMTKMiGH/3u9/ND3/4wxxxxBE59NBDi54DAAAAm02ZMiWtra39fm5ra2taWlr6/VwARrZRcQ3jI444IpVKpegZAAAAsFWXXnpppk6dmnK53C/n1dfXp6Ojo1/OAmB0GRXvMAYAAIChrLm5OYsWLeq38xYtWuRv2AKwQwRjAAAAGALmzZuXc889d6fPaWtry7x58/phEQCjkWAMAAAAQ0CpVEp7e3sWL16c+vr6mp9fX1+fxYsX55JLLkmpVBqAhQCMBoIxAAAADBGlUinz589PV1dXTR+E19ramrvuuivz588XiwHYKaPiQ+8AAABgOGlubs7KlSvT3d2d5cuXZ9WqVenu7k5fX1+SpKGhIc3NzZk+fXpmzpyZlpaWghcDMFIIxgAAADBEtbS05OKLL06SrF27NpMmTUqS9Pb2ZuLEiQUuA2CkckkKAAAAGAbq6uq2+mMA6E+CMQAAAAAASQRjAAAAAACqBGMAAAAAAJIIxgAAAAAAVAnGAAAAAAAkEYwBAAAAAKgSjAEAAAAASCIYAwAAAABQJRgDAAAAAJBEMAYAAAAAoEowBgAAAAAgiWAMAAAAAECVYAwAAAAAQBLBGAAAAACAKsEYAAAAAIAkgjEAAAAAAFWCMQAAAAAASQRjAAAAAACqBGMAAAAAAJIIxgAAAAAAVAnGAAAAAAAkEYwBAAAAAKgSjAEAAAAASCIYAwAAAABQJRgDAAAAAJBEMAYAAAAAoEowBgAAAAAgiWAMAAAAAECVYAwAAAAAQBLBGAAAAACAKsEYAAAAAIAkgjEAAAAAAFWCMQAAAAAASQRjAAAAAACqBGMAAAAAAJIIxgAAAAAAVAnGAAAAAAAkEYwBAAAAAKgSjAEAAAAASCIYAwAAAABQJRgDAAAAAJBEMAYAAAAAoEowBgAAAAAgiWAMAAAAAECVYAwAAAAAQBLBGAAAAACAKsEYAAAAAIAkgjEAAAAAAFWCMQAAAAAASQRjAAAAAACqBGMAAAAAAJIIxgAAAAAAVAnGAAAAAAAkEYwBAAAAAKgSjAEAAP6/9u49zuq6Tvz4e2DGAwNeCgFLbUAYl9riolCZgpcKcmt1zXTVbTfXQllFd0hXoJ+Soo8FyoeaaKW42GbtJdRH11XCbvJw6QLGgJeMQTG1BC8byEwy43B+f3SkDsNlZpgz3885PJ+PB4+H5zsz3/Oe85I5PN4cvgcAgIiwMAYAAAAAoMDCGAAAAACAiLAwBgAAAACgwMIYAAAAAICIsDAGAAAAAKDAwhgAAAAAgIiwMAYAAAAAoMDCGAAAAACAiLAwBgAAAACgwMIYAAAAAICIsDAGAAAAAKDAwhgAAAAAgIiwMAYAAAAAoMDCGAAAAACAiLAwBgAAAACgwMIYAAAAAICIsDAGAAAAAKDAwhgAAAAAgIiIqM56AAAAAIBy09bWFq+++mpERBx44IFRU1OT8UQAPcMrjAEAAAA6YfXq1XHZZZfFhAkTYuDAgTFo0KAYNGhQDBw4MCZMmBCXXXZZNDY2Zj0mwD6xMAYAAADYgzVr1sSkSZNi3LhxsXDhwli5cmW0trbu+Hhra2usXLkyFi5cGGPHjo1JkybFmjVrMpwYoPssjAEAAAB2IZ/Px/z582P8+PGxfPnyTn/d8uXLY/z48TF//vzI5/MlnBCg51kYAwAAAOwkn8/HpZdeGrNnz462trYuf31bW1vMnj07Lr30UktjoKxU/MI4n8/HfffdFyeffHK85S1vidra2viLv/iLuOiii+Kpp57KejwAAAAgQQsWLIjbbrttn89z2223xYIFC3pgIoDeUfEL4yuuuCLOPPPMePLJJ+Nv/uZv4tJLL43hw4fHokWLYuzYsfHoo49mPSIAAACQkDVr1sScOXN67Hxz5sxxTWOgbFRnPUApvfDCC3HzzTdHXV1dNDY2xsEHH7zjYzfddFN8+tOfjhtvvDEWL16c4ZQAAABASqZPn96ty1DsTltbW0yfPj0eeuihHjsnQKlU9CuMN2zYENu3b4/jjz++aFkcEfGRj3wkIiJefPHFLEYDAAAAErR69eouvcFdZy1fvjwaGxt7/LwAPa2iF8b19fVxwAEHxMMPPxxbtmwp+th3v/vdiIh4//vfn8VoAAAAQIJK+a+Q/QtnoBxU9CUpBg0aFPPnz4/LL788Ro0aFaeffnocdNBB0djYGD/84Q/j4osvjunTp2c9JgAAAJCIFStWlOW5AXpKRS+MIyJmzJgRhx9+eHzqU5+KL3/5yzuOn3DCCXHeeedFdXV5PQT5fD5aWlqyHqPX9eS1o/Y3bW1t0dzcnPUYveLPv8/95XtOmR5p0SMteqRFj7TokRY90qJH6bW1tZX0zenWrFkTmzdvLrtdBOyL2traqKqqynoMuqDif0LNnTs3rr/++pg7d258/OMfj0MOOSRWr14dM2bMiJNOOinuvffeOO2007Ies9NaWlpi4MCBWY9BGVm0aFEsWrQo6zF63dChQ7MegT+jR1r0SIseadEjLXqkRY+06FGetm3bFoccckjWY0Cv2rp1awwYMCDrMeiCir6G8YMPPhif/exnY/r06TFr1qw44ogjYuDAgXHCCSfEd77znaipqYnLL7886zEBAAAAAJJQ0a8wvv/++yMi4uSTT+7wscMOOyxGjRoVv/zlL2Pr1q1l86rd2tra2Lp1a9Zj9LoZM2bsl6+S7QlTp06Nm266KesxekVzc/OOV1ps3LjR32BmTI+06JEWPdKiR1r0SIseadGj9Nra2mLo0KHR2tpakvPncrnYuHGjS1KwX6mtrc16BLqoon9CvfED/sUXX9zlx1988cXo06dP1NTU9OZY+6Sqqmq//ENBOTVKTU1NzX75/8yAAQP2y+87VXqkRY+06JEWPdKiR1r0SIsepTN69OhYuXJlyc598MEHl+TcAD2loi9Jcfzxx0dExI033hibN28u+tiXv/zleO655+K4446LXC6XxXgAAABAYo477riyPDdAT6noVxifddZZ8aUvfSkeeuihOProo+O0006LQw45JB555JH44Q9/GP37948bb7wx6zEBAACARFxwwQWxcOHCkp0bIHUV/Qrjvn37xve///2YN29eHH744fEf//EfcfPNN8eTTz4ZH//4x2PVqlXx7ne/O+sxAQAAgESMHTs2Jk6c2OPnnThxYowZM6bHzwvQ0yr6FcYRf7yg/KxZs2LWrFlZjwIAAACUgVtvvTXGjx8fbW1tPXK+mpqauO2223rkXAClVtGvMAYAAADoqtGjR8fcuXN77Hxz586Nd73rXT12PoBSsjAGAAAA2MnMmTPjkksu2efzTJ8+PWbOnNkDEwH0DgtjAAAAgJ1UVVXFwoULY968eVFTU9Plr6+pqYl58+bFLbfcElVVVSWYEKA0LIwBAAAAdqGqqipmzZoVK1eu7NIb4U2cODFWrVoVs2bNsiwGyk7Fv+kdAAAAwL4YPXp0PPTQQ9HY2BiLFy+OFStWRGNjY7S2tkZERC6Xi9GjR8dxxx0XF1xwQYwZMybjiQG6z8IYAAAAoBPGjBkTX/jCFyIiYvPmzXHIIYdERMTGjRvj4IMPznAygJ7jkhQAAAAAXVRdXb3L/wYodxbGAAAAAABEhIUxAAAAAAAFFsYAAAAAAESEhTEAAAAAAAUWxgAAAAAARISFMQAAAAAABRbGAAAAAABEhIUxAAAAAAAFFsYAAAAAAESEhTEAAAAAAAUWxgAAAAAARISFMQAAAAAABRbGAAAAAABEhIUxAAAAAAAFFsYAAAAAAESEhTEAAAAAAAUWxgAAAAAARISFMQAAAAAABRbGAAAAAABEhIUxAAAAAAAFFsYAAAAAAESEhTEAAAAAAAUWxgAAAAAARISFMQAAAAAABRbGAAAAAABEhIUxAAAAAAAFFsYAAAAAAESEhTEAAAAAAAUWxgAAAAAARISFMQAAAAAABRbGAAAAAABEhIUxAAAAAAAFFsYAAAAAAESEhTEAAAAAAAUWxgAAAAAARISFMQAAAAAABRbGAAAAAABEhIUxAAAAAAAFFsYAAAAAAESEhTEAAAAAAAUWxgAAAAAARISFMQAAAAAABRbGAAAAAABEhIUxAAAAAAAFFsYAAAAAAESEhTEAAAAAAAUWxgAAAAAARISFMQAAAAAABRbGAAAAAABEhIUxAAAAAAAFFsYAAAAAAESEhTEAAAAAAAUWxgAAAAAARISFMQAAAAAABRbGAAAAAABEhIUxAAAAAAAFFsYAAAAAAESEhTEAAAAAAAUWxgAAAAAARISFMQAAAAAABRbGAAAAAABEhIUxAAAAAAAFFsYAAAAAAESEhTEAAAAAAAUWxgAAAAAARISFMQAAAAAABRbGAAAAAABEhIUxAAAAAAAFFsYAAAAAAESEhTEAAAAAAAUWxgAAAAAARISFMQAAAAAABRbGAAAAAABERER11gMAAAAAwL5oa2uLV199NSIiDjzwwKipqcl4IihfXmEMAAAAQNlZvXp1XHbZZTFhwoQYOHBgDBo0KAYNGhQDBw6MCRMmxGWXXRaNjY1Zjwllx8IYAAAAgLKxZs2amDRpUowbNy4WLlwYK1eujNbW1h0fb21tjZUrV8bChQtj7NixMWnSpFizZk2GE0N5sTAGAAAAIHn5fD7mz58f48ePj+XLl3f665YvXx7jx4+P+fPnRz6fL+GEUBksjAEAAABIWj6fj0svvTRmz54dbW1tXf76tra2mD17dlx66aWWxrAXFb8w3r59e9x6661xzDHHRG1tbRx00EExadKk+Pa3v531aAAAAAB0woIFC+K2227b5/PcdtttsWDBgh6YCCpXRS+M8/l8nH322XHppZfGli1b4pOf/GScc8458eSTT8bpp58et956a9YjAgAAALAHa9asiTlz5vTY+ebMmeOaxrAHFb0wvvfee+Pee++N448/PtauXRsLFy6MO+64Ix577LGoq6uLK664IjZs2JD1mAAAAADsxvTp07t1GYrdaWtri+nTp/fY+aDSVPTC+Fvf+lZERHzmM5+J/v377zh+6KGHxowZM2Lbtm1x1113ZTUeAAAAAHuwevXqLr3BXWctX748Ghsbe/y8UAkqemH8wgsvRETE8OHDO3zsjWM//OEPe3UmAAAAADpn8eLFZXluKGcVvTA+9NBDIyLi6aef7vCxN479+te/7tWZAAAAAOicFStWlOW5oZxVZz1AKZ166qnxX//1XzF//vw45ZRTol+/fhER8fLLL8fNN98cERG///3vsxuwG/L5fLS0tGQ9Rq/ryWsV7W/a2tqiubk56zF6xZ9/n/vL95wyPdKiR1r0SIseadEjLXqkRY+06FF6bW1tJX1zujVr1sTmzZujurqi12OZq62tjaqqqqzHoAuq8vl8PushSuX111+PyZMnx49+9KMYOXJkfOhDH4q2trb45je/GUOHDo01a9ZEv3794g9/+EPWo3Zac3NzDBw4MOsxMnfxxRfHbbfdlvUYSbrkkkvii1/8YtZjAAAAAMTWrVtjwIABWY9BF1T0JSmqq6vj/vvvj2uuuSb69OkTd9xxR9x3331x+umnxz333BMREUOGDMl4SgAAAACANFT8a+5zuVx89rOfjc9+9rNFx3/84x9HRMT48eMzmKr7amtrY+vWrVmP0etmzJgRixYtynqMsjR16tS46aabsh6jVzQ3N8fQoUMjImLjxo3+BjNjeqRFj7TokRY90qJHWvRIix5p0aP02traYujQodHa2lqS8+dyudi4caNLUpRYbW1t1iPQRfvt74ivf/3rERFxzjnnZDxJ11RVVe2XT0I1NTVZj1C2ampq9sv/ZwYMGLBfft+p0iMteqRFj7TokRY90qJHWvRIix6lM3r06Fi5cmXJzn3wwQeX5NxQzir6khQREVu2bOlw7J577onFixfHhAkT4qMf/WgGUwEAAACwN8cdd1xZnhvKWcW/wvg973lPHHnkkfH2t789+vXrFz//+c/jxz/+cRx11FGxZMmS6Nu3b9YjAgAAALALF1xwQSxcuLBk5wY6qvhXGP/t3/5tvPDCC3HXXXfFLbfcEhs3boyrrroqfvnLX0ZdXV3W4wEAAACwG2PHjo2JEyf2+HknTpwYY8aM6fHzQiWo+FcYX3PNNXHNNddkPQYAAAAA3XDrrbfG+PHjo62trUfOV1NTE7fddluPnAsqUcW/whgAAACA8jV69OiYO3duj51v7ty58a53vavHzgeVxsIYAAAAgKTNnDkzLrnkkn0+z/Tp02PmzJk9MBFULgtjAAAAAJJWVVUVCxcujHnz5kVNTU2Xv76mpibmzZsXt9xyS1RVVZVgQqgcFsYAAAAAJK+qqipmzZoVK1eu7NIb4U2cODFWrVoVs2bNsiyGTqj4N70DAAAAoHKMHj06HnrooWhsbIzFixfHihUrorGxMVpbWyMiIpfLxejRo+O4446LCy64IMaMGZPxxFBeLIwBAAAAKDtjxoyJL3zhCxERsXnz5jjkkEMiImLjxo1x8MEHZzgZlDeXpAAAAACgrFVXV+/yv4GuszAGAAAAACAiLIwBAAAAACiwMAYAAAAAICIsjClT27dvz3qEZHlsAAAAAOguC2PKQi6XK7rd2tqa0STp27ZtW9Htfv36ZTQJAAAAAOXGwpiysPPSs6WlJaNJ0rfzY2NhDAAAAEBnWRhTFg499NCi288++2xGk6TvueeeK7o9aNCgjCYBAAAAoNxYGFMWRo4cWXS7qakpo0nSt27duqLb9fX1GU0CAAAAQLmxMKYs7Lz03LhxY2zZsiWjadK1ZcuW2LRpU9ExC2MAAAAAOsvCmLJw1FFHRVVVVdGxnV9JS8fHpE+fPjF8+PCMpgEAAACg3FgYUxZyuVzU1dUVHXvwwQczmiZdy5YtK7pdV1cXuVwuo2kAAAAAKDcWxpSNKVOmFN1esmRJRpOka+fHZOfHDAAAAAD2xMKYsnHWWWcV3V61alU89dRTGU2TnvXr18cjjzxSdGznxwwAAAAA9sTCmLJx4oknxuDBg4uOLVy4MKNp0nPrrbcW3R4yZEhMmjQpo2kAAAAAKEcWxpSN6urqOPPMM4uOLVy4MB599NGMJkrH2rVrOyzPP/rRj0Z1dXVGEwEAAABQjiyMKStXXHFF0Zu4tbe3xyWXXBLbt2/PcKpsbd++PS655JJob2/fcSyXy8UVV1yR4VQAAAAAlCMLY8rKiBEj4sorryw69tBDD8W0adP2y6Xx9u3bY9q0abF8+fKi4zNnzowRI0ZkNBUAAAAA5crCmLIza9asqKurKzq2aNGi/W5p/MayeNGiRUXHhw0bFrNmzcpoKgAAAADKmYUxZae2tjbuuOOODtfnXbRoUZx00kmxdu3ajCbrPWvXro2TTjqpw7K4uro6br/99ujfv39GkwEAAABQziyMKUuTJ0+Ob3zjGx2WxsuXL49x48bFjBkzYv369RlNVzrr16+PGTNmxLhx4zpchqK6ujq+8Y1vxOTJkzOaDgAAAIByZ2FM2TrjjDN2uTRub2+Pm2++OUaOHBnHHntszJ8/P1atWhVbtmzJaNLu27JlS6xatSrmz58fxx57bIwcOTJuvvnmoje4i/jTsviMM87IaFIAAAAAKkH13j8F0nXGGWfE9773vbjoootiw4YNHT7+yCOPxCOPPBKzZ8+OiIghQ4ZEfX19HHHEEVFbWxu5XC769Enj7022b98e27Zti5aWlnjuuedi3bp1sWnTpr1+3bBhw+L222/3ymIAAAAA9pmFMWVv8uTJ8fjjj8f8+fNjwYIFsW3btt1+7qZNmzq1hC0HuVwuZs6cGbNmzXLNYgAAAAB6RBovrYR91L9//7j22mvjsccei2nTpsXgwYOzHqlkhgwZEtOmTYvHHnssrr32WstiAAAAAHqMhTEVZcSIEfGlL30pfvvb38YPfvCDmDZtWgwfPjyqqqqyHq3bqqqqYvjw4TFt2rT4wQ9+EM8//3x86UtfihEjRmQ9GgAAAAAVxiUpqEjV1dVxyimnxCmnnBIREdu2bYunn3461q1bF+vWrYuXX345XnvttXjttdcynrRYv379ol+/fjFo0KCor6+P+vr6GD58eORyuaxHAwAAAGA/YGHMfiGXy8WoUaNi1KhRWY8CAAAAAMlySQoAAAAAACLCwhgAAAAAgAILYwAAAAAAIsLCGAAAAACAAgtjAAAAAAAiwsIYAAAAAIACC2MAAAAAACLCwhgAAAAAgAILYwAAAAAAIsLCGAAAAACAAgtjAAAAAAAiwsIYAAAAAIACC2MAAAAAACLCwhgAAAAAgAILYwAAAAAAIsLCGAAAAACAAgtjAAAAAAAiwsIYAAAAAIACC2MAAAAAACIiojrrAYD9z7Zt2+Kpp56KdevWRVNTU7z00kvx2muvxbZt2/bpvG1tbTv+e8aMGVFTU7NP58vlctGvX7849NBDY+TIkVFfXx9HHXVU5HK5fTpvavRIix5p0SMteqRFj7TokRY90qJHWvRIS6l69LT9pUcqqvL5fD7rIYDK9vrrr8dPfvKTWLJkSSxdujSeeeaZKNcfPVVVVVFXVxdTpkyJs846K0488cSori6vv3vTIy16pEWPtOiRFj3Sokda9EiLHmnRIy160Cl5gBJZt25dftq0afnBgwfnI6Iifw0ePDg/bdq0fFNTU9YP917pkRY90qJHWvRIix5p0SMteqRFj7TokRY96AoLY6DHNTc356+++ur8AQcckPkTRm/9yuVy+auvvjrf3Nyc9cPfgR5p0SMteqRFj7TokRY90qJHWvRIix5p0YPucEkKoEd9//vfjwsvvDCeeeaZvX7u0KFDY+TIkXHkkUdGbW1tHHDAAdGnTxrvxbl9+/ZobW2NlpaWePbZZ6OpqSk2bty4168bNmxY3H777TF58uRemHLv9NCjFPTQoxT00KMU9NCjFPTQoxT00KMUKq3H2rVr43e/+120tbWVZY+ykvXGGqgc9913X766unq3f8t37LHH5ufPn59fuXJlfvPmzVmP22WbN2/Or1y5Mj9//vz8Mcccs9vvs7q6On/fffdlPa4eevQqPdKiR1r0SIseadEjLXqkRY+06JGd9vb2/MyZM/MRseOxLbce5cbCGOgRu3sy6tu3b76hoSG/fv36rEfscU1NTfmGhoZ83759k3tS0kOPrOmRFj3Sokda9EiLHmnRIy16pEWP3tHS0pL/2Mc+tuN7+N3vfrfLz0u5RzmyMAb22dKlS3f5ZDRp0qT82rVrsx6v5NauXZufNGnSLp+Uli5d2uvz6KFHSvRIix5p0SMteqRFj7TokRY90qJH6bzwwgv5d7/73Tu+h2HDhu31a1LrUa4sjIF90tzcnK+rq+vww3jq1Kn59vb2rMfrNe3t7fmpU6d2eByGDRuWb2lp6bU59PgjPdKiR1r0SIseadEjLXqkRY+06JEWPXreo48+2uF7Offcczv1tan0KGcWxsA+ufrqqyviyagn7O5Jac6cOb02gx5/okda9EiLHmnRIy16pEWPtOiRFj3SokfPWbZsWf6ggw7q8L3ccsstnT5HCj3KmYUx0G3r1q3L53K5oh++kyZNKrsno57U3t6enzhxYtFjksvl8k1NTSW/bz060iMteqRFj7TokRY90qJHWvRIix5p0WPfLVq0aLdv1veLX/yiS+fKske5szAGum3atGlFP3j79u1bdtdEKoU1a9Z0uND+tGnTSn6/euyaHmnRIy16pEWPtOiRFj3Sokda9EiLHt3T3t6ev/LKK3e5KI6IfP/+/fOtra1dPm9WPcqdhTHQLW1tbfnBgwcX/dBtaGjIeqxkNDQ0FD02Q4YMybe1tZXs/vTYMz3Sokda9EiLHmnRIy16pEWPtOiRFj26pqWlJX/mmWfudlkcEfmJEyd2+/y93aMSWBgD3fLggw92+AG+fv36rMdKRlNTU4fH5wc/+EHJ7k+PPdMjLXqkRY+06JEWPdKiR1r0SIseadGj81544YX8u9/97j0uiyMif+WVV3b7Pnq7RyXoEwDdsGTJkqLbxx57bBx11FEZTZOeESNGxDHHHFN0bOfHrCfpsWd6pEWPtOiRFj3Sokda9EiLHmnRIy16dM5jjz0W73nPe+LnP/950fE+fTquK4877rhu309v96gEFsZAtyxdurTo9llnnZXRJOna+THZ+THrSXrsnR5p0SMteqRFj7TokRY90qJHWvRIix57tmzZsnjf+94XzzzzTNHxgw8+OG644YYOn//e9753n+6vN3tUAgtjoMu2bdvW4Yf6Bz7wgYymSdcHP/jBotvPPPNMbNu2rcfvR4/O0SMteqRFj7TokRY90qJHWvRIix5p0WP3Fi1aFKeeemps2bKl6PiwYcPif//3f6O2trbD8cMOO2yf7rO3elQKC2Ogy5566qnI5/NFx44++uiMpklXfX190e3t27fH008/3eP3o0fn6JEWPdKiR1r0SIseadEjLXqkRY+06NHR9u3bY+bMmXHhhRdGe3t70cfe8573xE9/+tN4xzveEStWrCj62L5cjuINvdWjUlgYA122bt26ottDhw6NAw88MKNp0nXQQQfFkCFDio7t/Nj1BD06R4+06JEWPdKiR1r0SIseadEjLXqkRY9iLS0tcfbZZ8fnPve5XX787rvvjqFDh0ZElGRh3Fs9KoWFMdBlTU1NRbdHjhyZ0STp2/lvMUvxhKRH5+mRFj3Sokda9EiLHmnRIy16pEWPtOjxJ6+88kr84Q9/2O3Hjz766Dj11FPjpZdeil//+tdFH+uJhXFE7/SoFBbGQJe99NJLRbePPPLIjCZJ3xFHHFF0++WXX+7x+9Cj8/RIix5p0SMteqRFj7TokRY90qJHWvT4kyOOOCK++93vxre+9a0YNmzYLj/ngQceiMGDBxcd69+/f4wZM6bHZvhzpehRKSyMgS577bXXim7vfEF6/mTnx2bnx64n6NF5eqRFj7TokRY90qJHWvRIix5p0SMt+3uP9vb2omsVV1VVxWmnnRaPP/54zJkzp1PnGD9+fNTU1PTIPL3Ro1JUZz0AUH52fifRAw44IKNJ0pfL5Ypul+IJSY/O0yMteqRFj7TokRY90qJHWvRIix5p2R96tLa2RmNjY9Gvxx57LF599dVoa2uLiIiampo48MAD4y//8i9jzJgxMWbMmHjb297WqfP31OUoInqnR6WwMAb2WZ8+/rHC7mTx2Oixe3qkRY+06JEWPdKiR1r0SIseadEjLZXcY/Xq1bF48eL4+te/Hq+88soeP7etrS1eeeWVWL58eSxfvrxL99OTC2P/r3aehTEAAAAAsEevv/56/Nu//Vt8+ctfjtWrV/f4+T/84Q/Hgw8+WPSq6fe+9709fj/snYUxAAAAALBbK1asiH/6p3+KxsbGkt3H9773vRg1alS86U1vihUrVsSwYcPisMMOK9n9sXsWxgAAAABABy+//HLMmjUr7rzzzj1+3tFHH73j+sRjxoyJww8/fMc1g7dt2xbPP/98NDY2xnXXXdfhust/7le/+lVERHzwgx+Md77znT33jdAlFsYAAAAAQJHVq1fHRz7ykXj++ed3+fEjjzwyzj///PjEJz4RI0aM2OO5xo0bF4MGDYqrrrqqU/e9bNmyePzxx+Mf/uEfYuzYsV0dnX3kas8AAAAAwA4PPPBAnHDCCbtcFr/zne+M+++/P55++umYO3fuXpfFERH5fD7e9773dTh+0003xf3337/LVxM///zzccIJJ8QDDzzQvW+CbrMwBgAAAAAiIuI73/lOnHbaadHc3Fx0fMCAAXHDDTfEI488Eh/60Ieib9++nT7n//t//2+XxxsaGuJDH/pQPPLII3HDDTfEgAEDij7e3Nwcp59+enznO9/p+jdCt1kYAwAAAADx8MMPx5lnnhltbW1FxydOnBhPPPFEXH755VFTU9Olc7766qsxb968DsefeOKJHf9dU1MTl19+eTzxxBNxwgknFH1ea2trnHnmmfHwww936X7pPgtjAAAAANjP/d///V+cd955HZbF5557bixbtiyOPPLIbp13V5esGDduXIwaNarD8SOPPDIefPDBOPfcc4uOt7W1xXnnnRe///3vuzUDXVMxC+Ovfe1rcdFFF8X48eMjl8tFVVVVfOUrX9nt52/ZsiU+/elPR11dXeRyuRg2bFj8y7/8S2zdurX3hgb2aMOGDVFVVVX0q6amJg4//PA4++yzY+XKlft0/vPPPz+qqqpiw4YNPTNwhdMjLXqkRY+06JEWPdKiR1r0SIseadGjd+Xz+Zg6dWr85je/KTp+wQUXxN133x25XK5b512xYkW8+OKLHY7/9Kc/3e3X5HK5uPvuu+OCCy4oOv6b3/wmpk6dGvl8vluz0HnVWQ/QU6666qp45pln4tBDD423vOUt8cwzz+z2c5ubm+PEE0+M1atXx+TJk+Pcc8+NX/7yl3HDDTfET37yk3jooYeiX79+vTg9sCcjRoyIj3/84xHxx9+/q1atiiVLlsQ3v/nNePDBB2PSpEkZT7h/0SMteqRFj7TokRY90qJHWvRIix5p0aN3LFq0KO69996iYyeddFLccccdXbpW8Z/b3RvdfeELX4gDDjhgj1/bt2/fuOOOO2L9+vXxk5/8ZMfxe+65J+68886YOnVqt2aicypmYXznnXdGfX191NXVxfz582P27Nm7/dzPfe5zsXr16pg5c2bMnz9/x/FZs2bFggUL4qabbtrj1wO9a+TIkXHNNdcUHXvj9/nVV19d9ORB6emRFj3Sokda9EiLHmnRIy16pEWPtOhRei0tLR32YG9+85vja1/7WreXxRG7f6O7yy67rFNf37dv3/ja174WY8aMiVdeeWXH8dmzZ8ff/d3fRW1tbbdnY88q5pIUH/jAB6Kurm6vn5fP5+POO++MgQMHxtVXX130sauvvjoGDhwYd955Z6nGBHrIJz/5yYiIWLVqVdHxl156KRoaGmL48OGRy+ViyJAhcfbZZ8ejjz5a9HnDhg2Lf//3f4+IiOHDh+/4J04nnXRSr8xfafRIix5p0SMteqRFj7TokRY90qJHWvToWV/5yleKFrIREXfddVccfvjh3T5nZ97orjOOOOKIWLx4cdGxl19+eUc/SqNiXmHcWevWrYvf/va3MWXKlBgwYEDRxwYMGBDHH398LF26NJ599tluX8wb6D3V1X/6Mfbiiy/GcccdF+vXr4+TTjopzjnnnHj66afjnnvuie9973uxdOnSHe+22tDQEF/5yleisbEx/vmf/zkOOeSQiPjjHxzoPj3Sokda9EiLHmnRIy16pEWPtOiRFj32XXt7e9x4441Fx0499dQ47bTT9um8XXmju705/fTT49RTT437779/x7Ebb7wxLrzwwn16BTS7t18ujCMi6uvrd/nx+vr6WLp0aaxbt87CGBL2xr8EeOMJPyJi5syZsX79+pg9e3b867/+647j//M//xMf/vCH4x//8R/jySefjD59+kRDQ0OsXr06Ghsbo6GhYb/8g0FP0iMteqRFj7TokRY90qJHWvRIix5p0aPnfOtb34r169cXHbviiiv26ZzdeaO7vbn88suLFsZNTU3x7W9/O84444xun5Pd2+8Wxps3b46IiIMPPniXHz/ooIOKPi81+Xw+Wlpash6D/VxbW1uv3l9TU9OOa1a98SYHP/rRj2Lo0KHx+c9/PiIiWltb4z//8z9j0KBBcdVVVxV9/V/91V/FBz/4wVi2bFk8/PDDMXHixF6d/8+1tbVFc3Nzj5+zN+mx93P2Jj32fs7epMfez9mb9Nj7OXuTHns/Z2/SY+/n7E167P2cvUmPvZ+zN+mx93Pui2984xtFt8eNGxcnn3xyt8+3L290tyennHJKjB07NlavXr3j2H//939bGJfIfrcwLnctLS0xcODArMeAXrV+/fq49tpri44ddthhsXz58hg5cmRERPzqV7+K1157LU4++eRdXvj+5JNPjmXLlsXq1asz/QPCokWLYtGiRZndf0/QIy16pEWPtOiRFj3Sokda9EiLHmnRo7R2ftXvhRdeGFVVVd0+376+0d3uVFVVxYUXXhgXX3zxjmM/+9nP9umc7F7FvOldZ73xyuLdvYJ4y5YtRZ8HZG/KlCmRz+cjn8/Hpk2b4vOf/3xs2rQpTjvttNi6dWtE/On37tChQ3d5jre85S1Fn0f36ZEWPdKiR1r0SIseadEjLXqkRY+06FE6L7zwQjzzzDNFx/78Mh9d1VNvdLc7O8+2YcOG2LhxY4+cm2L73SuM37h28RvXMt7Z3q5xnLXa2todPxAhKzNmzMjsb0UHDx4cV1xxRWzevDmuv/76uOqqq+Lmm2/ecTmZ3T1ZvPDCCxHxp8vOZGXq1Klx00039eg59eg+Pf5Ij9LQoyM9uk+PP9KjNPToSI/u0+OP9CgNPTralx47v0L3wAMPjLe//e3dnqUn3+huV97xjnfEwIEDi/ZiP/vZz/b5DfroaL9cGL/1rW+Nhx9+OJqbm2PAgAE7Ptbc3BwPP/xwDB8+PNk3vKuqqiqaGbJQU1OT9Qjxmc98JhYvXhxf/OIXo6GhIUaNGhX9+vWLX/ziF9HS0tLhnyH9+Mc/joiIsWPH7jj2xruptre399bYUVNT0+O/h/XoPj3+SI/S0qP4nFnTo/icWdOj+JxZ06P4nFnTo/icWdOj+JxZ06P4nN3V2NhYdHvChAk7HpeuKsUb3e2sb9++MWHChPjRj36049jq1astjEtgv7skRVVVVXzqU5+KrVu3xnXXXVf0seuuuy62bt0aU6dOzWg6oLP69+8fM2fOjLa2trjuuuvigAMOiHPPPTdeeumlDv8E5oEHHoilS5fGyJEj4/jjj99x/M1vfnNERDz77LO9Onsl0iMteqRFj7TokRY90qJHWvRIix5p0aNnvPrqq0W3u/viyVK90d2u7Dyjf4VfGhWzML7zzjvj/PPPj/PPPz+WLFnS4didd96543OvvPLKGDNmTCxYsCCmTJkSs2fPjilTpsSCBQtiwoQJ0dDQkNF3AXTFhRdeGG9961vjq1/9aqxfvz4WLFgQRx11VFx//fXx/ve/Pz7zmc/EeeedF3/9138dtbW1cdddd0WfPn/6sXfKKafsOM/s2bPj+uuvj7vvvjurb6fs6ZEWPdKiR1r0SIseadEjLXqkRY+06LHvxowZE+ecc06cfvrpMXny5HjXu97VrfOU6o3udmX06NExefLkOP300+Occ86JMWPG9Ph9EBH5CvGJT3wiHxG7/fWJT3yi6PN///vf5xsaGvJHHnlkvqamJv+2t70tf/nll+e3bNmSzTcAZeTiiy8u+v118cUXl+R+nn766XxE5KdMmbLbz1m4cGE+IvJ///d/n8/n8/kXX3wxf9lll+Xr6uryNTU1+UMPPTT/sY99LL927dpdfv3nPve5fH19fb6mpiYfEfkTTzyxR7+H3nis9Og8PfTQY/f00EOP3dNDDz12Tw899Ni9SuqxO1u2bNnlHu6JJ57o1Tk6I+vHqpxUzMIY6D1+yHbe/vAHhHKiR1r0SIseadEjLXqkRY+06JEWPdKyP/QYPHhwh2XxuHHjenWGzsr6sSonFXNJCgAAAACgd/TGG92RDQtjAAAAAKDT8r34Rnf0PgtjAAAAAKDTevON7uh9FsYAAAAAQKe8+uqrMW/evA7Hn3jiiQymoRQsjAEAAACAThkxYkSHY+PGjYtRo0ZlMA2lYGEMAAAAAOyVN7rbP1gYAwAAAAB75I3u9h8WxgAAAADAHnmju/2HhTEAAAAAsFve6G7/YmEMAAAAAOyWN7rbv1gYA/ts+/btWY+QrCweGz12T4+06JEWPdKiR1r0SIseadEjLXqkpVJ6/OpXv6qIN7rz/2rnWRgDXZbL5Yput7a2ZjRJ+rZt21Z0u1+/fj1+H3p0nh5p0SMteqRFj7TokRY90qJHWvRISyX0yOfz0dDQ0OF4Ob7RXW/0qBQWxkCX7fxDtaWlJaNJ0rfzY1OKJyQ9Ok+PtOiRFj3Sokda9EiLHmnRIy16pKUSemzatCmefPLJomNvetObyvKN7nqjR6WwMAa67NBDDy26/eyzz2Y0Sfqee+65otuDBg3q8fvQo/P0SIseadEjLXqkRY+06JEWPdKiR1oqocfQoUPj8ccfjzlz5kQul4sBAwbEmjVrevQ+ektv9KgUFsZAl40cObLodlNTU0aTpG/dunVFt+vr63v8PvToPD3Sokda9EiLHmnRIy16pEWPtOiRlkrp0b9//7j22mvjsccei69+9atxxBFH9Ph99Ibe6FEpLIyBLtv5h+rGjRtjy5YtGU2Tri1btsSmTZuKjpXiCUmPztEjLXqkRY+06JEWPdKiR1r0SIseaanEHiNGjIiPfvSjJTl3qfVWj0phYQx02VFHHRVVVVVFx3b+mzo6PiZ9+vSJ4cOH9/j96NE5eqRFj7TokRY90qJHWvRIix5p0SMteqSlt3pUCgtjoMtyuVzU1dUVHXvwwQczmiZdy5YtK7pdV1fX4R1se4IenaNHWvRIix5p0SMteqRFj7TokRY90qJHWnqrR6WwMAa6ZcqUKUW3lyxZktEk6dr5Mdn5MetJeuydHmnRIy16pEWPtOiRFj3Sokda9EiLHmnpzR6VwMIY6Jazzjqr6PaqVaviqaeeymia9Kxfvz4eeeSRomM7P2Y9SY890yMteqRFj7TokRY90qJHWvRIix5p0SMtvd2jElgYA91y4oknxuDBg4uOLVy4MKNp0nPrrbcW3R4yZEhMmjSpZPenx57pkRY90qJHWvRIix5p0SMteqRFj7TokZbe7lER8gDdNG3atHxE7PjVt2/f/Nq1a7MeK3Nr1qzJ9+3bt+ixmTZtWsnvV49d0yMteqRFj7TokRY90qJHWvRIix5p0SMtWfUodxbGQLc1NTXlc7lc0Q/eSZMm5dvb27MeLTPt7e35iRMnFj0muVwu39TUVPL71qMjPdKiR1r0SIseadEjLXqkRY+06JEWPdKSZY9yZ2EM7JOrr7666IdvROSnTp26Xz4ptbe356dOndrh8ZgzZ06vzaDHn+iRFj3Sokda9EiLHmnRIy16pEWPtOiRlhR6lDMLY2CfNDc35+vq6vb7J6XdPRkNGzYs39LS0mtz6PFHeqRFj7TokRY90qJHWvRIix5p0SMteqQllR7lzMIY2GdLly7NV1dXd/hhPHHixPyaNWuyHq/k1qxZ0+GfuUREvrq6Or906dJen0cPPVKiR1r0SIseadEjLXqkRY+06JEWPdKSWo9yZWEM9Ij77rtvl09Kffv2zTc0NFTkNYKampryDQ0NHS6g/8aT0X333ZfZbHrokTU90qJHWvRIix5p0SMteqRFj7TokZaUe5QjC2Ogx+zuSemNX8ccc0x+3rx5+ZUrV+Y3b96c9bhdtnnz5vzKlSvz8+bNyx9zzDG7/T5TeTLSQ4/epEda9EiLHmnRIy16pEWPtOiRFj3SUm49yk1VPp/PB0AP+f73vx8XXXRRbNiwYa+fO2TIkKivr48jjjgiamtrI5fLRZ8+fUo/ZCds3749tm3bFi0tLfHcc8/FunXrYtOmTXv9umHDhsXtt98ekydP7oUp904PPUpBDz1KQQ89SkEPPUpBDz1KQQ89SkGPtHqUlaw31kDlaWlpyc+ZMyefy+V2+7d8lfYrl8vl58yZk+QF9PVIix5p0SMteqRFj7TokRY90qJHWvRIix50h4UxUDJNTU35adOm5QcPHpz5E0apfg0ZMiQ/bdq0srgGlB5p0SMteqRFj7TokRY90qJHWvRIix5p0YOucEkKoORef/31eOihh2LJkiWxdOnS2LBhQ5Trj56qqqoYNmxYTJkyJc4666yYNGlSVFdXZz1Wl+iRFj3Sokda9EiLHmnRIy16pEWPtOiRFj3oDAtjoNdt27Ytnn766Vi3bl2sW7cuXn755Xjttdfitddey3q0Iv369Yt+/frFoEGDor6+Purr62P48OGRy+WyHq1H6ZEWPdKiR1r0SIseadEjLXqkRY+06JEWPdgVC2MAAAAAACIiIo23OwQAAAAAIHMWxgAAAAAARISFMQAAAAAABRbGAAAAAABEhIUxAAAAAAAFFsYAAAAAAESEhTEAAAAAAAUWxgAAAAAARISFMQAAAAAABRbGAAAAAABEhIUxAAAAAAAFFsYAAAAAAESEhTEAAAAAAAUWxgAAAAAARISFMQAAAAAABRbGAAAAAABEhIUxAAAAAAAFFsYAAAAAAESEhTEAAAAAAAUWxgAAAAAARISFMQAAAAAABRbGAAAAAABEhIUxAAAAAAAFFsYAAAAAAESEhTEAAAAAAAUWxgAAAAAARISFMQAAAAAABRbGAAAAAABEhIUxAAAAAAAFFsYAAAAAAESEhTEAAAAAAAUWxgAAAAAARISFMQAAAAAABRbGAAAAAABEhIUxAAAAAAAFFsYAAAAAAESEhTEAAAAAAAUWxgAAAAAARISFMQAAAAAABRbGAAAAAABEhIUxAAAAAAAFFsYAAAAAAESEhTEAAAAAAAUWxgAAAAAARISFMQAAAAAABRbGAAAAAABEhIUxAAAAAAAFFsYAAAAAAESEhTEAAAAAAAUWxgAAAAAARISFMQAAAAAABRbGAAAAAABEhIUxAAAAAAAFFsYAAAAAAESEhTEAAAAAAAUWxgAAAAAARISFMQAAAAAABRbGAAAAAABEhIUxAAAAAAAFFsYAAAAAAESEhTEAAAAAAAUWxgAAAAAARISFMQAAAAAABRbGAAAAAABEhIUxAAAAAAAFFsYAAAAAAESEhTEAAAAAAAUWxgAAAAAARISFMQAAAAAABf8fxPX9yns/d8oAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1400x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize QNN with random weights\n",
    "params = np.random.uniform(size=(layers*loading_qubits, 3), requires_grad=True) #The number of parameters is 3*number of layers\n",
    "print(qml.draw_mpl(QNN, show_all_wires=True)(params,training_states[0],dm_labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(params, x, y, dm_labels):\n",
    "    \"\"\"Cost function to be minimized.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        x (array[float]): 2-d array of input vectors\n",
    "        y (array[float]): 1-d array of targets\n",
    "        state_labels (array[float]): array of state representations for labels\n",
    "\n",
    "    Returns:\n",
    "        float: loss value to be minimized\n",
    "    \"\"\"\n",
    "    # Compute prediction for each input in data batch\n",
    "    loss = 0.0\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        f = QNN(params, x[i], dm_labels[int(y[i])])\n",
    "        loss = loss + (1 - f) ** 2\n",
    "    return loss / len(x)\n",
    "\n",
    "def test(params, x, y, dm_labels):\n",
    "    \"\"\"\n",
    "    Tests on a given set of data.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        x (array[float]): 2-d array of input vectors\n",
    "        y (array[float]): 1-d array of targets\n",
    "        state_labels (array[float]): 1-d array of state representations for labels\n",
    "\n",
    "    Returns:\n",
    "        predicted (array([int]): predicted labels for test data\n",
    "        output_states (array[float]): output quantum states from the circuit\n",
    "    \"\"\"\n",
    "    fidelity_values = []\n",
    "    predicted = []\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        fidel_function = lambda y: QNN(params, x[i], y)\n",
    "        fidelities = [fidel_function(dm) for dm in dm_labels] \n",
    "        best_fidel = np.argmax(fidelities)\n",
    "\n",
    "        predicted.append(best_fidel)\n",
    "        fidelity_values.append(fidelities)\n",
    "\n",
    "    return np.array(predicted), np.array(fidelity_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Cost: 0.325183 | Train accuracy: 0.479000 | Test Accuracy: 0.501500\n",
      "Epoch:  1 | Loss: 0.217134 | Train accuracy: 0.717000 | Test accuracy: 0.694500\n",
      "Epoch:  2 | Loss: 0.212261 | Train accuracy: 0.734000 | Test accuracy: 0.695500\n",
      "Epoch:  3 | Loss: 0.211097 | Train accuracy: 0.731000 | Test accuracy: 0.702000\n",
      "Epoch:  4 | Loss: 0.210846 | Train accuracy: 0.739000 | Test accuracy: 0.710500\n",
      "Epoch:  5 | Loss: 0.211266 | Train accuracy: 0.747000 | Test accuracy: 0.715500\n",
      "Epoch:  6 | Loss: 0.211613 | Train accuracy: 0.747000 | Test accuracy: 0.715500\n",
      "Epoch:  7 | Loss: 0.211821 | Train accuracy: 0.747000 | Test accuracy: 0.718500\n",
      "Epoch:  8 | Loss: 0.211705 | Train accuracy: 0.744000 | Test accuracy: 0.715500\n",
      "Epoch:  9 | Loss: 0.212024 | Train accuracy: 0.749000 | Test accuracy: 0.717500\n",
      "Epoch: 10 | Loss: 0.211737 | Train accuracy: 0.742000 | Test accuracy: 0.719500\n",
      "Epoch: 11 | Loss: 0.211246 | Train accuracy: 0.733000 | Test accuracy: 0.705500\n",
      "Epoch: 12 | Loss: 0.211499 | Train accuracy: 0.734000 | Test accuracy: 0.712000\n",
      "Epoch: 13 | Loss: 0.211889 | Train accuracy: 0.744000 | Test accuracy: 0.713500\n",
      "Epoch: 14 | Loss: 0.212055 | Train accuracy: 0.744000 | Test accuracy: 0.712000\n",
      "Epoch: 15 | Loss: 0.212038 | Train accuracy: 0.741000 | Test accuracy: 0.713500\n",
      "Epoch: 16 | Loss: 0.211986 | Train accuracy: 0.744000 | Test accuracy: 0.714000\n",
      "Epoch: 17 | Loss: 0.211949 | Train accuracy: 0.742000 | Test accuracy: 0.713000\n",
      "Epoch: 18 | Loss: 0.211944 | Train accuracy: 0.740000 | Test accuracy: 0.713000\n",
      "Epoch: 19 | Loss: 0.211961 | Train accuracy: 0.739000 | Test accuracy: 0.710500\n",
      "Epoch: 20 | Loss: 0.211988 | Train accuracy: 0.737000 | Test accuracy: 0.710500\n"
     ]
    }
   ],
   "source": [
    "#Train using Adam optimizer and evaluate the classifier\n",
    "learning_rate = 0.05\n",
    "epochs = 20\n",
    "batch_size = 8\n",
    "opt = AdamOptimizer(learning_rate, beta1=0.9, beta2=0.999)\n",
    "\n",
    "np.random.seed(88)\n",
    "params = np.random.uniform(size=(layers*loading_qubits, 3), requires_grad=True) \n",
    "\n",
    "predicted_train, fidel_train = test(params, x_train, y_train, dm_labels)\n",
    "accuracy_train = accuracy_score(y_train, predicted_train)\n",
    "\n",
    "predicted_test, fidel_test = test(params, x_test, y_test, dm_labels)\n",
    "accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "\n",
    "initial_predictions = predicted_test\n",
    "\n",
    "loss = cost(params, test_states, y_test, dm_labels)\n",
    "\n",
    "#These are the predictions with random weights\n",
    "print(\"Epoch: {:2d} | Cost: {:3f} | Train accuracy: {:3f} | Test Accuracy: {:3f}\".format(0, loss, accuracy_train, accuracy_test))\n",
    "\n",
    "# Now results with optimization\n",
    "for it in range(epochs): #In each epoch I go through all the training data which is splitted in batches\n",
    "    for Xbatch, ybatch in iterate_minibatches(x_train, y_train, batch_size=batch_size): #AFTER INTRODUCING A BATCH, PARAMETERS ARE UPDATED\n",
    "        params, _, _, _ = opt.step(cost, params, Xbatch, ybatch, dm_labels)\n",
    "\n",
    "    predicted_train, fidel_train = test(params, x_train, y_train, dm_labels)\n",
    "    accuracy_train = accuracy_score(y_train, predicted_train) \n",
    "    loss = cost(params, x_train, y_train, dm_labels)\n",
    "\n",
    "    predicted_test, fidel_test = test(params, x_test, y_test, dm_labels)\n",
    "    accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "    res = [it + 1, loss, accuracy_train, accuracy_test]\n",
    "    print(\"Epoch: {:2d} | Loss: {:3f} | Train accuracy: {:3f} | Test accuracy: {:3f}\".format(*res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Loss: 0.211988 | Train accuracy: 0.737000 | Test accuracy: 0.710500\n"
     ]
    }
   ],
   "source": [
    "print(\"Epoch: {:2d} | Loss: {:3f} | Train accuracy: {:3f} | Test accuracy: {:3f}\".format(*res))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\chi=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi = 2\n",
    "\n",
    "training_approx_states = []\n",
    "test_approx_states = []\n",
    "\n",
    "for element in training_states:\n",
    "    mps = MPS(element, L, d, chi)\n",
    "    approximation = MPS_contraction(mps, L, d)\n",
    "    approximation = np.reshape(approximation, (1, -1))\n",
    "    training_approx_states.append(approximation[0])\n",
    "\n",
    "for element in test_states:\n",
    "    mps = MPS(element, L, d, chi)\n",
    "    approximation = MPS_contraction(mps, L, d)\n",
    "    approximation = np.reshape(approximation, (1, -1))\n",
    "    test_approx_states.append(approximation[0])\n",
    "\n",
    "x_train = np.array(training_approx_states, requires_grad=False)\n",
    "x_test = np.array(test_approx_states, requires_grad=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classical benchmark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9375\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(training_approx_states, y_train)\n",
    "y_pred = model.predict(test_approx_states)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_2 = training_approx_states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Cost: 0.325183 | Train accuracy: 0.479000 | Test Accuracy: 0.501500\n",
      "Epoch:  1 | Loss: 0.192891 | Train accuracy: 0.844000 | Test accuracy: 0.869000\n",
      "Epoch:  2 | Loss: 0.190542 | Train accuracy: 0.838000 | Test accuracy: 0.858500\n",
      "Epoch:  3 | Loss: 0.189786 | Train accuracy: 0.842000 | Test accuracy: 0.862500\n",
      "Epoch:  4 | Loss: 0.189153 | Train accuracy: 0.846000 | Test accuracy: 0.860000\n",
      "Epoch:  5 | Loss: 0.188780 | Train accuracy: 0.851000 | Test accuracy: 0.865000\n",
      "Epoch:  6 | Loss: 0.187786 | Train accuracy: 0.847000 | Test accuracy: 0.865000\n",
      "Epoch:  7 | Loss: 0.185721 | Train accuracy: 0.850000 | Test accuracy: 0.869500\n",
      "Epoch:  8 | Loss: 0.186039 | Train accuracy: 0.854000 | Test accuracy: 0.876500\n",
      "Epoch:  9 | Loss: 0.184689 | Train accuracy: 0.859000 | Test accuracy: 0.875000\n",
      "Epoch: 10 | Loss: 0.183792 | Train accuracy: 0.863000 | Test accuracy: 0.881000\n",
      "Epoch: 11 | Loss: 0.183447 | Train accuracy: 0.856000 | Test accuracy: 0.876500\n",
      "Epoch: 12 | Loss: 0.183412 | Train accuracy: 0.858000 | Test accuracy: 0.875000\n",
      "Epoch: 13 | Loss: 0.183409 | Train accuracy: 0.858000 | Test accuracy: 0.875000\n",
      "Epoch: 14 | Loss: 0.183429 | Train accuracy: 0.859000 | Test accuracy: 0.874000\n",
      "Epoch: 15 | Loss: 0.183447 | Train accuracy: 0.861000 | Test accuracy: 0.876500\n",
      "Epoch: 16 | Loss: 0.183426 | Train accuracy: 0.861000 | Test accuracy: 0.877000\n",
      "Epoch: 17 | Loss: 0.183369 | Train accuracy: 0.862000 | Test accuracy: 0.877500\n",
      "Epoch: 18 | Loss: 0.183315 | Train accuracy: 0.861000 | Test accuracy: 0.877500\n",
      "Epoch: 19 | Loss: 0.183271 | Train accuracy: 0.861000 | Test accuracy: 0.877500\n",
      "Epoch: 20 | Loss: 0.183234 | Train accuracy: 0.860000 | Test accuracy: 0.875000\n"
     ]
    }
   ],
   "source": [
    "#Train using Adam optimizer and evaluate the classifier\n",
    "learning_rate = 0.05\n",
    "epochs = 20\n",
    "batch_size = 8\n",
    "opt = AdamOptimizer(learning_rate, beta1=0.9, beta2=0.999)\n",
    "\n",
    "np.random.seed(88)\n",
    "params = np.random.uniform(size=(layers*loading_qubits, 3), requires_grad=True) \n",
    "\n",
    "predicted_train, fidel_train = test(params, x_train, y_train, dm_labels)\n",
    "accuracy_train = accuracy_score(y_train, predicted_train)\n",
    "\n",
    "predicted_test, fidel_test = test(params, x_test, y_test, dm_labels)\n",
    "accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "\n",
    "initial_predictions = predicted_test\n",
    "\n",
    "loss = cost(params, test_states, y_test, dm_labels)\n",
    "\n",
    "#These are the predictions with random weights\n",
    "print(\"Epoch: {:2d} | Cost: {:3f} | Train accuracy: {:3f} | Test Accuracy: {:3f}\".format(0, loss, accuracy_train, accuracy_test))\n",
    "\n",
    "# Now results with optimization\n",
    "for it in range(epochs): #In each epoch I go through all the training data which is splitted in batches\n",
    "    for Xbatch, ybatch in iterate_minibatches(x_train, y_train, batch_size=batch_size): #AFTER INTRODUCING A BATCH, PARAMETERS ARE UPDATED\n",
    "        params, _, _, _ = opt.step(cost, params, Xbatch, ybatch, dm_labels)\n",
    "\n",
    "    predicted_train, fidel_train = test(params, x_train, y_train, dm_labels)\n",
    "    accuracy_train = accuracy_score(y_train, predicted_train) \n",
    "    loss = cost(params, x_train, y_train, dm_labels)\n",
    "\n",
    "    predicted_test, fidel_test = test(params, x_test, y_test, dm_labels)\n",
    "    accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "    res = [it + 1, loss, accuracy_train, accuracy_test]\n",
    "    print(\"Epoch: {:2d} | Loss: {:3f} | Train accuracy: {:3f} | Test accuracy: {:3f}\".format(*res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26938966383054375\n",
      "0.4329252552066784\n",
      "0.6028065859076303\n"
     ]
    }
   ],
   "source": [
    "print(fidelity(training_states[0],save_1))\n",
    "print(fidelity(training_states[0],save_2))\n",
    "print(fidelity(save_2,save_1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\chi=4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi = 4\n",
    "\n",
    "training_approx_states = []\n",
    "test_approx_states = []\n",
    "\n",
    "for element in training_states:\n",
    "    mps = MPS(element, L, d, chi)\n",
    "    approximation = MPS_contraction(mps, L, d)\n",
    "    approximation = np.reshape(approximation, (1, -1))\n",
    "    training_approx_states.append(approximation[0])\n",
    "\n",
    "for element in test_states:\n",
    "    mps = MPS(element, L, d, chi)\n",
    "    approximation = MPS_contraction(mps, L, d)\n",
    "    approximation = np.reshape(approximation, (1, -1))\n",
    "    test_approx_states.append(approximation[0])\n",
    "\n",
    "x_train = np.array(training_approx_states, requires_grad=False)\n",
    "x_test = np.array(test_approx_states, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Cost: 0.325183 | Train accuracy: 0.479000 | Test Accuracy: 0.501500\n",
      "Epoch:  1 | Loss: 0.193354 | Train accuracy: 0.834000 | Test accuracy: 0.854500\n",
      "Epoch:  2 | Loss: 0.192115 | Train accuracy: 0.822000 | Test accuracy: 0.845000\n",
      "Epoch:  3 | Loss: 0.188651 | Train accuracy: 0.853000 | Test accuracy: 0.874000\n",
      "Epoch:  4 | Loss: 0.181733 | Train accuracy: 0.870000 | Test accuracy: 0.882500\n",
      "Epoch:  5 | Loss: 0.180990 | Train accuracy: 0.875000 | Test accuracy: 0.893000\n",
      "Epoch:  6 | Loss: 0.179863 | Train accuracy: 0.871000 | Test accuracy: 0.881500\n",
      "Epoch:  7 | Loss: 0.179330 | Train accuracy: 0.871000 | Test accuracy: 0.877500\n",
      "Epoch:  8 | Loss: 0.179278 | Train accuracy: 0.870000 | Test accuracy: 0.878500\n",
      "Epoch:  9 | Loss: 0.179285 | Train accuracy: 0.876000 | Test accuracy: 0.887000\n",
      "Epoch: 10 | Loss: 0.179328 | Train accuracy: 0.883000 | Test accuracy: 0.896000\n",
      "Epoch: 11 | Loss: 0.179226 | Train accuracy: 0.889000 | Test accuracy: 0.900500\n",
      "Epoch: 12 | Loss: 0.179077 | Train accuracy: 0.894000 | Test accuracy: 0.904000\n",
      "Epoch: 13 | Loss: 0.179064 | Train accuracy: 0.894000 | Test accuracy: 0.905500\n",
      "Epoch: 14 | Loss: 0.179084 | Train accuracy: 0.894000 | Test accuracy: 0.906000\n",
      "Epoch: 15 | Loss: 0.179110 | Train accuracy: 0.896000 | Test accuracy: 0.907000\n",
      "Epoch: 16 | Loss: 0.179135 | Train accuracy: 0.898000 | Test accuracy: 0.907000\n",
      "Epoch: 17 | Loss: 0.179159 | Train accuracy: 0.898000 | Test accuracy: 0.907500\n",
      "Epoch: 18 | Loss: 0.179181 | Train accuracy: 0.899000 | Test accuracy: 0.907500\n",
      "Epoch: 19 | Loss: 0.179201 | Train accuracy: 0.899000 | Test accuracy: 0.908000\n",
      "Epoch: 20 | Loss: 0.179218 | Train accuracy: 0.899000 | Test accuracy: 0.909000\n"
     ]
    }
   ],
   "source": [
    "#Train using Adam optimizer and evaluate the classifier\n",
    "learning_rate = 0.05\n",
    "epochs = 20\n",
    "batch_size = 8\n",
    "opt = AdamOptimizer(learning_rate, beta1=0.9, beta2=0.999)\n",
    "\n",
    "np.random.seed(88)\n",
    "params = np.random.uniform(size=(layers*loading_qubits, 3), requires_grad=True) \n",
    "\n",
    "predicted_train, fidel_train = test(params, x_train, y_train, dm_labels)\n",
    "accuracy_train = accuracy_score(y_train, predicted_train)\n",
    "\n",
    "predicted_test, fidel_test = test(params, x_test, y_test, dm_labels)\n",
    "accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "\n",
    "initial_predictions = predicted_test\n",
    "\n",
    "loss = cost(params, test_states, y_test, dm_labels)\n",
    "\n",
    "#These are the predictions with random weights\n",
    "print(\"Epoch: {:2d} | Cost: {:3f} | Train accuracy: {:3f} | Test Accuracy: {:3f}\".format(0, loss, accuracy_train, accuracy_test))\n",
    "\n",
    "# Now results with optimization\n",
    "for it in range(epochs): #In each epoch I go through all the training data which is splitted in batches\n",
    "    for Xbatch, ybatch in iterate_minibatches(x_train, y_train, batch_size=batch_size): #AFTER INTRODUCING A BATCH, PARAMETERS ARE UPDATED\n",
    "        params, _, _, _ = opt.step(cost, params, Xbatch, ybatch, dm_labels)\n",
    "\n",
    "    predicted_train, fidel_train = test(params, x_train, y_train, dm_labels)\n",
    "    accuracy_train = accuracy_score(y_train, predicted_train) \n",
    "    loss = cost(params, x_train, y_train, dm_labels)\n",
    "\n",
    "    predicted_test, fidel_test = test(params, x_test, y_test, dm_labels)\n",
    "    accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "    res = [it + 1, loss, accuracy_train, accuracy_test]\n",
    "    print(\"Epoch: {:2d} | Loss: {:3f} | Train accuracy: {:3f} | Test accuracy: {:3f}\".format(*res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.958\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(training_approx_states, y_train)\n",
    "y_pred = model.predict(test_approx_states)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\chi=32$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi = 32\n",
    "\n",
    "training_approx_states = []\n",
    "test_approx_states = []\n",
    "\n",
    "for element in training_states:\n",
    "    mps = MPS(element, L, d, chi)\n",
    "    approximation = MPS_contraction(mps, L, d)\n",
    "    approximation = np.reshape(approximation, (1, -1))\n",
    "    training_approx_states.append(approximation[0])\n",
    "\n",
    "for element in test_states:\n",
    "    mps = MPS(element, L, d, chi)\n",
    "    approximation = MPS_contraction(mps, L, d)\n",
    "    approximation = np.reshape(approximation, (1, -1))\n",
    "    test_approx_states.append(approximation[0])\n",
    "\n",
    "x_train = np.array(training_approx_states, requires_grad=False)\n",
    "x_test = np.array(test_approx_states, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Cost: 0.325183 | Train accuracy: 0.479000 | Test Accuracy: 0.501500\n",
      "Epoch:  1 | Loss: 0.186045 | Train accuracy: 0.934000 | Test accuracy: 0.938500\n",
      "Epoch:  2 | Loss: 0.173697 | Train accuracy: 0.933000 | Test accuracy: 0.948500\n",
      "Epoch:  3 | Loss: 0.167176 | Train accuracy: 0.947000 | Test accuracy: 0.958000\n",
      "Epoch:  4 | Loss: 0.166484 | Train accuracy: 0.948000 | Test accuracy: 0.957000\n",
      "Epoch:  5 | Loss: 0.166608 | Train accuracy: 0.946000 | Test accuracy: 0.957500\n",
      "Epoch:  6 | Loss: 0.166744 | Train accuracy: 0.945000 | Test accuracy: 0.954500\n",
      "Epoch:  7 | Loss: 0.166837 | Train accuracy: 0.945000 | Test accuracy: 0.954500\n",
      "Epoch:  8 | Loss: 0.166898 | Train accuracy: 0.946000 | Test accuracy: 0.953500\n",
      "Epoch:  9 | Loss: 0.166938 | Train accuracy: 0.945000 | Test accuracy: 0.953500\n",
      "Epoch: 10 | Loss: 0.166966 | Train accuracy: 0.946000 | Test accuracy: 0.953000\n",
      "Epoch: 11 | Loss: 0.166987 | Train accuracy: 0.946000 | Test accuracy: 0.952500\n",
      "Epoch: 12 | Loss: 0.167003 | Train accuracy: 0.947000 | Test accuracy: 0.952500\n",
      "Epoch: 13 | Loss: 0.167017 | Train accuracy: 0.947000 | Test accuracy: 0.952500\n",
      "Epoch: 14 | Loss: 0.167028 | Train accuracy: 0.947000 | Test accuracy: 0.952500\n",
      "Epoch: 15 | Loss: 0.167038 | Train accuracy: 0.947000 | Test accuracy: 0.952000\n",
      "Epoch: 16 | Loss: 0.167046 | Train accuracy: 0.947000 | Test accuracy: 0.951500\n",
      "Epoch: 17 | Loss: 0.167053 | Train accuracy: 0.946000 | Test accuracy: 0.951500\n",
      "Epoch: 18 | Loss: 0.167059 | Train accuracy: 0.946000 | Test accuracy: 0.951500\n",
      "Epoch: 19 | Loss: 0.167064 | Train accuracy: 0.946000 | Test accuracy: 0.950500\n",
      "Epoch: 20 | Loss: 0.167068 | Train accuracy: 0.946000 | Test accuracy: 0.950500\n"
     ]
    }
   ],
   "source": [
    "#Train using Adam optimizer and evaluate the classifier\n",
    "learning_rate = 0.05\n",
    "epochs = 20\n",
    "batch_size = 8\n",
    "opt = AdamOptimizer(learning_rate, beta1=0.9, beta2=0.999)\n",
    "\n",
    "np.random.seed(88)\n",
    "params = np.random.uniform(size=(layers*loading_qubits, 3), requires_grad=True) \n",
    "\n",
    "predicted_train, fidel_train = test(params, x_train, y_train, dm_labels)\n",
    "accuracy_train = accuracy_score(y_train, predicted_train)\n",
    "\n",
    "predicted_test, fidel_test = test(params, x_test, y_test, dm_labels)\n",
    "accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "\n",
    "initial_predictions = predicted_test\n",
    "\n",
    "loss = cost(params, test_states, y_test, dm_labels)\n",
    "\n",
    "#These are the predictions with random weights\n",
    "print(\"Epoch: {:2d} | Cost: {:3f} | Train accuracy: {:3f} | Test Accuracy: {:3f}\".format(0, loss, accuracy_train, accuracy_test))\n",
    "\n",
    "# Now results with optimization\n",
    "for it in range(epochs): #In each epoch I go through all the training data which is splitted in batches\n",
    "    for Xbatch, ybatch in iterate_minibatches(x_train, y_train, batch_size=batch_size): #AFTER INTRODUCING A BATCH, PARAMETERS ARE UPDATED\n",
    "        params, _, _, _ = opt.step(cost, params, Xbatch, ybatch, dm_labels)\n",
    "\n",
    "    predicted_train, fidel_train = test(params, x_train, y_train, dm_labels)\n",
    "    accuracy_train = accuracy_score(y_train, predicted_train) \n",
    "    loss = cost(params, x_train, y_train, dm_labels)\n",
    "\n",
    "    predicted_test, fidel_test = test(params, x_test, y_test, dm_labels)\n",
    "    accuracy_test = accuracy_score(y_test, predicted_test)\n",
    "    res = [it + 1, loss, accuracy_train, accuracy_test]\n",
    "    print(\"Epoch: {:2d} | Loss: {:3f} | Train accuracy: {:3f} | Test accuracy: {:3f}\".format(*res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
